[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "b-causal",
    "section": "",
    "text": "Inverse Probability of Treatment Weighting: A Practical Guide\n\n\n\n\n\n\nCausal Inference\n\n\nNZAVS\n\n\nMethods\n\n\n\n\n\n\n\n\n\nMay 11, 2023\n\n\nJoseph Bulbulia\n\n\n\n\n\n\n\n\n\n\n\n\nInstitutional Trust in New Zealand Pre/Post COVID-19 Pandemic\n\n\nNew Zealand Attitudes and Values Study: Years 2019-2022 N = 42,681\n\n\n\nNZAVS\n\n\nCOVID\n\n\nDescriptive\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\nJoseph Bulbulia, Chris G Sibley\n\n\n\n\n\n\n\n\n\n\n\n\nM-Bias: Confounding Control Using Three Waves of Panel Data\n\n\n\n\n\n\nCausal Inference\n\n\nOutcome-wide Science\n\n\nMethods\n\n\n\n\n\n\n\n\n\nNov 22, 2022\n\n\nJoseph Bulbulia\n\n\n\n\n\n\n\n\n\n\n\n\nChanges in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022\n\n\nNew Zealand Attitudes and Values Study (Panel), N = 38,551 (28,642 retained)\n\n\n\nNZAVS\n\n\nCOVID\n\n\nDescriptive\n\n\n\n\n\n\n\n\n\nNov 18, 2022\n\n\nJoseph Bulbulia, Chris G Sibley\n\n\n\n\n\n\n\n\n\n\n\n\nNZAVS Virtue Measures introduced in 2018\n\n\n\n\n\n\nBackground\n\n\nNZAVS\n\n\n\n\n\n\n\n\n\nNov 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Problem of Treatment Confounder Feedback\n\n\n\n\n\n\nCausal Inference\n\n\nMethods\n\n\n\n\n\n\n\n\n\nNov 6, 2022\n\n\nJoseph Bulbulia\n\n\n\n\n\n\n\n\n\n\n\n\nG-computation in NZAVS Studies\n\n\n\n\n\n\nCausal Inference\n\n\nNZAVS\n\n\nMethods\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\nJoseph Bulbulia\n\n\n\n\n\n\n\n\n\n\n\n\nOutcome-wide Science in NZAVS Studies\n\n\n\n\n\n\nCausal Inference\n\n\nNZAVS\n\n\nOutcome-wide Science\n\n\nMethods\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\nJoseph Bulbulia\n\n\n\n\n\n\n\n\n\n\n\n\nNZAVS Retention Graph\n\n\n\n\n\n\nBackground\n\n\nNZAVS\n\n\n\n\n\n\n\n\n\nNov 4, 2022\n\n\nJoseph Bulbulia, Chris G Sibley\n\n\n\n\n\n\n\n\n\n\n\n\nThe New Zealand Attitudes and Values Study\n\n\n\n\n\n\nBackground\n\n\nNZAVS\n\n\n\n\n\n\n\n\n\nNov 2, 2022\n\n\nJoseph Bulbulia\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to the b-causal lab\n\n\n\n\n\n\nBackground\n\n\nLab\n\n\n\n\n\n\n\n\n\nOct 30, 2022\n\n\nJoseph Bulbulia\n\n\n\n\n\n\nNo matching items\n\nReuseCC BY-NC-SA 4.0"
  },
  {
    "objectID": "posts/outcomewide/outcome-wide.html",
    "href": "posts/outcomewide/outcome-wide.html",
    "title": "Outcome-wide Science in NZAVS Studies",
    "section": "",
    "text": "Figure 1: Confounding control using three waves of data & multiple imputation of responses lost-to-follow-up in which an unmeasured cause affects both selection and the outcome, introducing bias.\n\n\n\n\nConfounding occurs when the statistical association between indicators in the data do not reflect a causal association between parameters in a target population. A causal diagramme is a qualitative tool that enables us to quickly inspect sources of confounding.\nWe may represent our strategy for confounding control using the causal graph presented in Figure 1.\nFigure 2 presents another causal graph in which selection may introduce bias.\n\n\n\n\n\nFigure 2: Confounding control using three waves of data & multiple imputation of responses lost-to-follow-up in which the outcome affects selection, introducing bias\n\n\n\n\nWe define an exposure or treatment by \\(A\\). We define \\(\\boldsymbol{Y}\\) as the set of all well-being outcomes contained in the NZAVS. Our interest is in consistently estimating the causal effect of congregation size on each of these outcomes. To consistently estimate the causal effect of an exposure \\(A=1\\) on the vector of well-being outcomes \\(\\boldsymbol{Y}\\) we must ensure that we have included a set of confounders that will prevent any statistical association between \\(A\\) and \\(Y\\) in the absence of causation. A statistical association in the absence of a causal association may arise in one of three ways.: (1) \\(A\\) and \\(Y\\) share a common cause. (2) \\(A\\) and \\(Y\\) share a common effect. (3) There is confounding by descent, such that conditioning on a confounder introduces a statistical association between \\(A\\) and \\(Y\\) in the absence of a casual association (collider bias).\nTo address challenge (1) we may condition or stratify on all measured common causes of \\(A\\) and \\(Y\\). To address challenges (2) and (3), we must not condition on any effect or descendent of an effect. Note however that by conditioning on a descent of a common cause we may at least partially address conditioning by a common cause. This is because conditioning on the effect of a common cause may itself partially block the effect of the that common cause.\nIn NZAVS outcome-wide science studies we use a modified version of VanderWeele et al’s approach for estimating outcome-wide causal effects (VanderWeele, Mathur, and Chen 2020).\nVanderWeele’s approach utilises three waves of panel data collected within the same participants over time.\nCall \\(t-1\\) the baseline wave, \\(t_0\\) the exposure wave, and \\(t+1\\) the outcome measurement wave. First, we include at baseline indicators of all past outcomes \\(\\boldsymbol{Y}_{t-1}\\). Second, we include at baseline an indicator for the past exposure \\(A_{t-1}\\). Third, we include a rich set of baseline confounders \\(\\boldsymbol{L_{t-1}}\\). Of course, we cannot ensure that this strategy is sufficient to ensure no unmeasured confounding. However, on On VanderWeele’s strategy, for any unmeasured confounder to affect both the exposure/outcome association, it would need to do so independently of its effects on prior measurements of the exposure and (all) outcomes at baseline, in addition to all measured baseline confounders. Note also that by controlling for measured confounders the wave prior to exposure we avoid unwittingly conditioning on an effects of the exposure that subsequently affects the outcome – mediator bias. Note furthermore that by measuring the outcome in the year following the exposure, \\(Y_{t+1}\\), we ensure that the exposure temporally precedes the outcome, and is not, for example, an effect of the outcome. Finally, loss-to-follow-up or attrition, as well as survey non-response may introduce selection bias (represented by the boxed \\(S_{t+1}\\)). There are several ways in which uch selection bias may introduce confounding. In Figure 1, we note the prospect in which a novel common cause of \\(A\\) and \\(Y\\) called \\(U_s\\) may lead to a spurious association between \\(A\\) and \\(Y\\) if \\(S\\) is a collider of \\(A\\) and \\(U_s\\). To avoid selection bias we multiply impute the missing responses.\n\n\n\n\nReferences\n\nVanderWeele, Tyler J, Maya B Mathur, and Ying Chen. 2020. “Outcome-Wide Longitudinal Designs for Causal Inference: A New Template for Empirical Studies.” Statistical Science 35 (3): 437466.\n\nReuseCC BY-NC-SACitationBibTeX citation:@online{bulbulia2022,\n  author = {Joseph Bulbulia},\n  title = {Outcome-Wide {Science} in {NZAVS} {Studies}},\n  date = {2022-11-05},\n  url = {https://go-bayes.github.io/b-causal-lab/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJoseph Bulbulia. 2022. “Outcome-Wide Science in NZAVS\nStudies.” November 5, 2022. https://go-bayes.github.io/b-causal-lab/."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The purpose of this site is to convey research to a broader public."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About",
    "section": "Contact",
    "text": "Contact\nMy name is Joseph Bulbulia (Joe). I am a professor of psychology at Victoria of University in Wellington NZ, and an adjunct professor in Psychology at the University of Canterbury Here, and an associate researcher at the Max Planck Institute for Evolutionary Anthropology Here\nMy email address is: joseph.bulbulia@vuw.ac.nz"
  },
  {
    "objectID": "posts/covid-change/cv.html",
    "href": "posts/covid-change/cv.html",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "",
    "text": "New Zealanders report high levels of trust and satisfaction with the New Zealand Government’s response to COVID-19. However, levels of trust and satisfaction have waned somewhat from 2021 to 2022.1\nDespite relatively low mortality rates, New Zealanders do not generally believe that COVID-19 risks have been exaggerated. However, the perceived exaggeration of COVID-19 risks increased from 2021-2022.2\nThere has been an increase in belief that COVID-19 was manufactured in a laboratory.3\nResults remain unchanged in models that impute missing data arising from sample attrition."
  },
  {
    "objectID": "posts/covid-change/cv.html#purpose",
    "href": "posts/covid-change/cv.html#purpose",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Purpose",
    "text": "Purpose\nWe investigate changes in attitudes to COVID-19 from the Time 12 to the Time 13 waves of the New Zealand Attitudes and Values Study (NZAVS). The NZAVS is a national probability panel study of attitudes and values in New Zealanders, started by Chris G. Sibley in 2009 (see:NZAVS homepage and link)\nThere were \\(N = 38,551\\) participants who responded to the NZAVS at Time 12 and \\(n = 28,642\\) participants who responded at Time 13."
  },
  {
    "objectID": "posts/covid-change/cv.html#covid-attitude-items-repeated-in-nzavs-time-12-and-time-13",
    "href": "posts/covid-change/cv.html#covid-attitude-items-repeated-in-nzavs-time-12-and-time-13",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Covid attitude items repeated in NZAVS Time 12 and Time 13",
    "text": "Covid attitude items repeated in NZAVS Time 12 and Time 13\nThe NZAVS recorded the following four attitudes to COVID-19 in both Time 12 and Time 13:\nCovid risks are exaggerated\n\n“I think that health risks associated with COVID-19 have been wildly exaggerated.” (1-7)\n\nCovid created in a lab\n\n“I think it is quite likely that COVID-19 was created in a laboratory.” (1-7)\n\nCOVID-19 Trust Government response\n\n“I trust the Government to make sensible decisions about how to best manage COVID-19 in New Zealand.” (1-7)\n\nCOVID-19 Satisfied with Government response\n\n“The New Zealand government response to COVID-19.” (0-10)"
  },
  {
    "objectID": "posts/covid-change/cv.html#boxplot-indicates-decline-in-both-perceived-risks-of-covid-satisfaction-with-government-response",
    "href": "posts/covid-change/cv.html#boxplot-indicates-decline-in-both-perceived-risks-of-covid-satisfaction-with-government-response",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Boxplot indicates decline in both perceived risks of COVID & Satisfaction with Government Response",
    "text": "Boxplot indicates decline in both perceived risks of COVID & Satisfaction with Government Response\n\n\n\nIn 2021, beliefs that COVID=19 was created in a lab were low. Raw response data suggest that tjese beliefs increased from in 2022.\n\n\n\n\n\nFigure 1: Boxplot for Covid Created in a Lab attitudes: NZAVS Time 12 & NZAVS Time 13\n\n\n\n\nAlthough beliefs that risks for COVID-19 are low, raw response data suggest these beliefs increased between 2021 and 2022.\n\n\n\n\n\nFigure 2: Boxplot for Covid Risk Exaggerated attitudes: NZAVS Time 12 & NZAVS Time 13\n\n\n\n\nAlthough trust in the NZ government COVID-19 response is high, raw response data suggest trust dropped between 2021 and 2022.\n\n\n\n\n\nFigure 3: Boxplot for Trust Government Response attitudes: NZAVS Time 12 & NZAVS Time 13\n\n\n\n\n\n\n\nAlthough Satisfaction with the NZ Government response to COVID-19 is high, raw response data suggest satisfaction dropped between 2021 and 2022.\n\n\n\n\n\nFigure 4: Boxplot for Satisfied with Government Response attitudes: NZAVS Time 12 & NZAVS Time 13"
  },
  {
    "objectID": "posts/covid-change/cv.html#model",
    "href": "posts/covid-change/cv.html#model",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Model",
    "text": "Model\nNext, we formally model change in COVID attitudes using multilevel models.\n\n\n\nResults presented in Table 1 and Figure 5 show the magnitudes of change in response across the four indicators of COVID-19 attitudes.\n\n\n\n\n\n\nTable 1:  Model results \n  \n  \n    \n      Parameter\n      Risks Exaggerated\n      Created Lab\n      Trust Govt Response\n      Sat Govt Response\n    \n  \n  \n    (Intercept)\n2.10 (2.08, 2.12)\n2.98 (2.96, 3.00)\n5.65 (5.63, 5.66)\n7.99 (7.96, 8.01)\n    wave\n0.58 (0.56, 0.59)\n0.50 (0.48, 0.52)\n-0.90 (-0.92, -0.89)\n-1.54 (-1.57, -1.52)\n    \n\n\n\n\n    Observations\n64372\n65048\n65439\n66816\n  \n  \n    \n      \n    \n  \n  \n\n\n\n\n\n\n\n\n\n\nFigure 5: Predicted responses in Time 12 and Time 13"
  },
  {
    "objectID": "posts/covid-change/cv.html#findings",
    "href": "posts/covid-change/cv.html#findings",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Findings",
    "text": "Findings\nThese models indicate overall high levels of support for the New Zealand Government Response to COVID 19, that has somewhat waned between NZAVS Time 12 and 13 (October 2020 - October 2022). Notably, these models do not adjust for bias from NZAVS sample attrition.\nWe next investigate models that adjust for panel attrition by imputing missing responses."
  },
  {
    "objectID": "posts/covid-change/cv.html#follow-up-bayesian-models-impute-missing-outcomes-arising-from-loss-to-follow-up",
    "href": "posts/covid-change/cv.html#follow-up-bayesian-models-impute-missing-outcomes-arising-from-loss-to-follow-up",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Follow up: Bayesian models impute missing outcomes arising from loss to follow up",
    "text": "Follow up: Bayesian models impute missing outcomes arising from loss to follow up\nPanel studies follow the same people over time. There is typically attrition of any panel over time. Where attrition is related to the outcomes of interest, this can lead to selection bias. That is, responses can be higher or lower because the residual panel systematically differs from initial cohort.\nWe use Bayesian multilevel models to impute the missing data arising from panel attrition. Our models include a broad range of indicators measured in the baseline year (Time 12) that might affect panel attrition in the following year (Time 13)4. We did not estimate missing predictor values at baseline. These values were excluded. Although exclusion at baseline may result in departure from the population estimate, the time effect estimate is consistent for the population with full response information at baseline. We estimated these models using the brms package in R using the packages default weakly informative priors (Bürkner 2022).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: To handle panel attrition Bayesian models impute missing outcomes\n\n\n\n\nFigure 6 and Table 2 present the results of the Bayesian multilevel imputation models. These agree with the models that do not handle attrition. Conditional on the imputation model, then, we infer there was little bias in estimated average responses arising from panel attrition.\n\n\n\n\n\n\nTable 2:  Bayes models (missing data imputed) \n  \n  \n    \n      Parameter\n      Risks Exaggerated\n      Created Lab\n      Trust Govt Response\n      Sat Govt Response\n    \n  \n  \n    (Intercept)\n2.07 (2.05, 2.08)\n2.94 (2.93, 2.96)\n5.67 (5.65, 5.68)\n8.01 (7.99, 8.04)\n    wave\n0.58 (0.56, 0.60)\n0.51 (0.49, 0.53)\n-0.90 (-0.92, -0.88)\n-1.55 (-1.58, -1.52)\n    \n\n\n\n\n    Observations\n68638\n68638\n68638\n68638"
  },
  {
    "objectID": "posts/covid-change/cv.html#bayesian-models-do-change-inference",
    "href": "posts/covid-change/cv.html#bayesian-models-do-change-inference",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Bayesian models do change inference",
    "text": "Bayesian models do change inference\nOverall, New Zealanders do not perceive the risks of COVID-19 to be exaggerated. However, there was somewhat greater perception of exaggeration in 2022 compared with 2021. Here, we speculate about the causes of this dicline. COVID-19 only became widespread in New Zealand after the population was vaccinated. During 2022, about two-million New Zealanders reported testing positive for COVID-19 source, of whom 3239 died within 28 days of their positive test. This low death-to-case-positive ratio perhaps motivate the somewhat greater perception of risk-exaggeration in 2022. The causes of change in risk-exaggeration remain unclear. The overall high rate in the perception of risk accuracy implies effective science communication.\nIn 2022 beliefs that COVID-19 was manufactured in a laboratory increased. At present, there is some scientific disagreement about the origins of COVID-19 (see for example link), even if most evidence points to a natural origin source. Future NZAVS research will investigate whether growing beliefs in a laboratory origin are grounding in confidence in science or tendencies to conspiracy beliefs, or both.\nIn 2022, New Zealanders continued to express high levels of trust in the New Zealand Government’s response to COVID-19. However, levels of trust declined somewhat from where they were in 2021.\nSimilarly, in 2022, New Zealanders continued to express high levels of satisfaction with New Zealand Government’s response to COVID-19. However, levels of trust declined somewhat from where they were in 2021.\nHigh trust and satisfaction with the government’s COVID-19 response might be partially explained by New Zealand’s low COVID-19 death rate. Indeed, the low death rate might also explain waning trust and satisfaction. Suffering was averted. That is satisfying. The averted suffering is not directly observable – it was averted. As such, the averted suffering remains intellectual. By contrast, the economic and social fallout of the pandemic was experienced, and continues to be experienced.\nFuture NZAVS research will systematically investigate the causal basis of trust and satisfaction with the New Zealand Government’s COVID-19 response, which although falling, remains high.5"
  },
  {
    "objectID": "posts/covid-change/cv.html#appendix-a-descriptive-data",
    "href": "posts/covid-change/cv.html#appendix-a-descriptive-data",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Appendix A: Descriptive data",
    "text": "Appendix A: Descriptive data\nDemographic data are presented in ?@tbl-demo. Response data are presented in Table 3.\n\n\n?(caption)\n\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Time12, N = 38,5511\n      Time13, N = 28,6421\n    \n  \n  \n    Age\n55 (44, 63)\n58 (47, 65)\n    Gender3\n\n\n        Female\n24,569 (64%)\n18,313 (64%)\n        GenderDiverse\n165 (0.4%)\n125 (0.4%)\n        Male\n13,817 (36%)\n10,204 (36%)\n    EthnicCats\n\n\n        Euro\n32,311 (85%)\n24,487 (87%)\n        Maori\n3,374 (8.9%)\n2,346 (8.3%)\n        Pacific\n708 (1.9%)\n373 (1.3%)\n        Asian\n1,443 (3.8%)\n912 (3.2%)\n        Unknown\n715\n524\n    BornNZ\n30,248 (79%)\n22,595 (79%)\n        Unknown\n27\n16\n    Employed\n29,303 (77%)\n20,899 (74%)\n        Unknown\n287\n321\n    Edu\n7.00 (3.00, 8.00)\n7.00 (4.00, 8.00)\n        Unknown\n1,365\n101\n    Pol.Orient\n\n\n        1\n2,616 (7.1%)\n1,625 (5.9%)\n        2\n8,090 (22%)\n5,849 (21%)\n        3\n7,874 (21%)\n5,861 (21%)\n        4\n11,054 (30%)\n8,204 (30%)\n        5\n4,771 (13%)\n3,893 (14%)\n        6\n2,062 (5.6%)\n1,644 (6.0%)\n        7\n480 (1.3%)\n331 (1.2%)\n        Unknown\n1,604\n1,235\n    SDO\n2.00 (1.33, 2.83)\n2.00 (1.50, 2.83)\n        Unknown\n23\n26\n    RWA\n3.17 (2.50, 4.00)\n3.33 (2.50, 4.00)\n        Unknown\n76\n165\n    NZSEI13\n59 (44, 70)\n60 (45, 70)\n        Unknown\n349\n30\n    NZDep.2018\n4.00 (2.00, 7.00)\n4.00 (2.00, 7.00)\n        Unknown\n588\n828\n    Religious\n\n\n        0\n25,275 (67%)\n19,462 (68%)\n        1\n12,610 (33%)\n9,177 (32%)\n        Unknown\n666\n3\n    Partner\n28,267 (75%)\n20,828 (75%)\n        Unknown\n900\n887\n    Parent\n28,687 (75%)\n21,385 (75%)\n        Unknown\n80\n136\n    CONSCIENTIOUSNESS\n5.25 (4.50, 5.75)\n5.25 (4.50, 6.00)\n        Unknown\n290\n206\n    OPENNESS\n5.00 (4.25, 5.75)\n5.00 (4.25, 6.00)\n        Unknown\n291\n203\n    HONESTY_HUMILITY\n5.75 (4.75, 6.50)\n6.00 (5.00, 6.67)\n        Unknown\n301\n199\n    EXTRAVERSION\n3.75 (3.00, 4.75)\n3.75 (3.00, 4.50)\n        Unknown\n288\n210\n    NEUROTICISM\n3.50 (2.75, 4.25)\n3.25 (2.50, 4.25)\n        Unknown\n292\n208\n    AGREEABLENESS\n5.50 (4.75, 6.00)\n5.50 (4.75, 6.00)\n        Unknown\n291\n212\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\n\n\n\n\n\n\n\nTable 3:  Descriptive table \n  \n  \n    \n      Characteristic\n      Time12, N = 38,5511\n      Time13, N = 28,6421\n    \n  \n  \n    COVID.RisksExaggerated\n\n\n        1\n19,380 / 37,437 (52%)\n11,281 / 26,935 (42%)\n        2\n8,610 / 37,437 (23%)\n5,595 / 26,935 (21%)\n        3\n3,062 / 37,437 (8.2%)\n2,422 / 26,935 (9.0%)\n        4\n2,406 / 37,437 (6.4%)\n2,001 / 26,935 (7.4%)\n        5\n1,806 / 37,437 (4.8%)\n2,072 / 26,935 (7.7%)\n        6\n1,159 / 37,437 (3.1%)\n1,850 / 26,935 (6.9%)\n        7\n1,014 / 37,437 (2.7%)\n1,714 / 26,935 (6.4%)\n        Unknown\n1,114\n1,707\n    COVID.CreatedLab\n\n\n        1\n13,136 / 37,284 (35%)\n7,463 / 27,764 (27%)\n        2\n6,280 / 37,284 (17%)\n4,371 / 27,764 (16%)\n        3\n2,510 / 37,284 (6.7%)\n2,043 / 27,764 (7.4%)\n        4\n6,922 / 37,284 (19%)\n5,456 / 27,764 (20%)\n        5\n2,975 / 37,284 (8.0%)\n2,725 / 27,764 (9.8%)\n        6\n2,865 / 37,284 (7.7%)\n2,898 / 27,764 (10%)\n        7\n2,596 / 37,284 (7.0%)\n2,808 / 27,764 (10%)\n        Unknown\n1,267\n878\n    COVID.TrustGovtResponse\n\n\n        1\n1,213 / 38,123 (3.2%)\n2,733 / 27,316 (10%)\n        2\n1,379 / 38,123 (3.6%)\n2,240 / 27,316 (8.2%)\n        3\n1,760 / 38,123 (4.6%)\n2,179 / 27,316 (8.0%)\n        4\n2,357 / 38,123 (6.2%)\n2,346 / 27,316 (8.6%)\n        5\n5,182 / 38,123 (14%)\n4,575 / 27,316 (17%)\n        6\n12,833 / 38,123 (34%)\n8,060 / 27,316 (30%)\n        7\n13,399 / 38,123 (35%)\n5,183 / 27,316 (19%)\n        Unknown\n428\n1,326\n    COVID.SatGovtResponse\n7.99 (2.35)\n6.49 (3.08)\n        Unknown\n252\n125\n  \n  \n  \n    \n      1 n / N (%); Mean (SD)"
  },
  {
    "objectID": "posts/covid-change/cv.html#appendix-b-model-equations",
    "href": "posts/covid-change/cv.html#appendix-b-model-equations",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Appendix B: Model equations",
    "text": "Appendix B: Model equations\nModel 1\n\n\n\\[\n\\begin{aligned}\n  \\operatorname{COVID.RisksExaggerated}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{wave}), \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for Id j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nModel 2\n\n\n\\[\n\\begin{aligned}\n  \\operatorname{COVID.CreatedLab}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{wave}), \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for Id j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nModel 3\n\n\n\\[\n\\begin{aligned}\n  \\operatorname{COVID.TrustGovtResponse}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{wave}), \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for Id j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nModel 4\n\n\n\\[\n\\begin{aligned}\n  \\operatorname{COVID.SatGovtResponse}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1}(\\operatorname{wave}), \\sigma^2 \\right) \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for Id j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/covid-change/cv.html#appendix-c-all-covid-related-questions-only-four-items-repeated-in-2022",
    "href": "posts/covid-change/cv.html#appendix-c-all-covid-related-questions-only-four-items-repeated-in-2022",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Appendix C: All COVID-related questions (only four items repeated in 2022)",
    "text": "Appendix C: All COVID-related questions (only four items repeated in 2022)\nNZAVS Time 12 (2019-2020) contains more indicators of COVID attitudes than those presented above. Responses are graphed in Figure 7.6\n\n\n\n\n\nFigure 7: Attitudes to a broad range of COVID-19 attitudes measured in Time 12"
  },
  {
    "objectID": "posts/covid-change/cv.html#appendix-d-vacitiation-attitudes-in-the-time-13-sample",
    "href": "posts/covid-change/cv.html#appendix-d-vacitiation-attitudes-in-the-time-13-sample",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Appendix D: Vacitiation attitudes in the Time 13 sample",
    "text": "Appendix D: Vacitiation attitudes in the Time 13 sample\nIn Time 13, the NZAVS included four new items to to measure COVID-19 Vaccination attitudes. These are:\n\nVaccination Safe\n“It is safe for adults to get vaccinated for COVID-19 using the Pfizer vaccine (Pfizer is the vaccine used in New Zealand’s COVID-19 vaccine rollout).”\n\n\nVaccinated\n“Have you been vaccinated for COVID-19?”\n\n\nVaccinated Intend\n“If not, do you intend to get vaccinated for COVID-19?”\n\n\nReason for Vaccinated Refusal\n“If you are not, and do not intend to get, vaccinated for COVID-19, why not?”\nFigure 8 presents descriptive summaries of responses.\n\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 28,6421\n    \n  \n  \n    COVID.Vaccinated\n\n        0\n1,395 / 28,083 (5.0%)\n        1\n26,688 / 28,083 (95%)\n        Unknown\n559\n    COVID.VaccinatedIntend\n\n        0\n1,576 / 1,678 (94%)\n        1\n102 / 1,678 (6.1%)\n        Unknown\n26,964\n    COVID.VaccinationSafe\n\n        1\n1,058 / 27,199 (3.9%)\n        2\n566 / 27,199 (2.1%)\n        3\n551 / 27,199 (2.0%)\n        4\n1,657 / 27,199 (6.1%)\n        5\n1,927 / 27,199 (7.1%)\n        6\n6,595 / 27,199 (24%)\n        7\n14,845 / 27,199 (55%)\n        Unknown\n1,443\n  \n  \n  \n    \n      1 n / N (%)\n    \n  \n\n\nFigure 8: Vaccination attitudes 2021/22\n\n\n\nWe note that the vaccination intent question contains measurement error. Among the 26688 participants who indicated that they had been vaccinated, 283 (1%) indicated that they did not intend to be vaccinated.\nIt is therefore more informative to focus on those 1395 participants who were not vaccinated. Of these, 102 indended to be vaccinated. Thus, 7.3% of participants who reported they were not vaccinated intended to be vaccinated.\n\n\n\n\n\n\n\n  \n  \n    \n      \n      \n        COVID.Vaccinated\n      \n      Total\n    \n    \n      0\n      1\n      Unknown\n    \n  \n  \n    COVID.VaccinatedIntend\n\n\n\n\n        0\n1,293 (93%)\n283 (1.1%)\n0 (0%)\n1,576 (5.5%)\n        1\n102 (7.3%)\n0 (0%)\n0 (0%)\n102 (0.4%)\n        Unknown\n0 (0%)\n26,405 (99%)\n559 (100%)\n26,964 (94%)\n  \n  \n  \n\n\nFigure 9: Vaccination cross-tab Intent and Vaccination Status"
  },
  {
    "objectID": "posts/covid-change/cv.html#appendix-e-acknowledgments",
    "href": "posts/covid-change/cv.html#appendix-e-acknowledgments",
    "title": "Changes in Perceived Risks and Government Attitudes to COVID-19 in New Zealand: years 2021 - 2022",
    "section": "Appendix E: Acknowledgments",
    "text": "Appendix E: Acknowledgments\nWe are grateful to the maintainers of the following packages, which we use in our work.\nWe are grateful for Templeton Religion Trust Grant: 0418 for supporting this work.7\n\n\nR version 4.2.0 (2022-04-22)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Monterey 12.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] splines   stats     graphics  grDevices datasets  utils     methods  \n[8] base     \n\nother attached packages:\n [1] gtsummary_1.6.2.9004  equatiomatic_0.3.1    CMAverse_0.1.0       \n [4] gt_0.7.0              report_0.5.5          ggeffects_1.1.4      \n [7] katex_1.4.0           patchwork_1.1.2       lubridate_1.8.0      \n[10] parameters_0.19.0     kableExtra_1.3.4      table1_1.4.2         \n[13] ggokabeito_0.1.0      brms_2.18.0           geepack_1.3.9        \n[16] cmdstanr_0.5.3        rstan_2.21.7          StanHeaders_2.21.0-7 \n[19] lme4_1.1-31           Matrix_1.5-1          ggpubr_0.4.0         \n[22] formula.tools_1.7.1   gghighlight_0.4.0     marginaleffects_0.7.1\n[25] skimr_2.1.4           naniar_0.6.1          conflicted_1.1.0     \n[28] Amelia_1.8.0          Rcpp_1.0.9            miceadds_3.15-21     \n[31] mice_3.14.0           stdReg_3.4.1          here_1.0.1           \n[34] janitor_2.1.0         devtools_2.4.5        usethis_2.1.6        \n[37] remotes_2.4.2         forcats_0.5.2         stringr_1.4.1        \n[40] dplyr_1.0.10          purrr_0.3.5           readr_2.1.3          \n[43] tidyr_1.2.1           tibble_3.1.8          ggplot2_3.4.0        \n[46] tidyverse_1.3.2      \n\nloaded via a namespace (and not attached):\n  [1] estimability_1.4.1   metadat_1.2-0        msm_1.6.9           \n  [4] coda_0.19-4          visdat_0.5.3         knitr_1.40          \n  [7] dygraphs_1.1.1.6     multcomp_1.4-20      data.table_1.14.4   \n [10] inline_0.3.19        generics_0.1.3       callr_3.7.2         \n [13] TH.data_1.1-1        future_1.29.0        commonmark_1.8.1    \n [16] EValue_4.1.3         tzdb_0.3.0           webshot_0.5.4       \n [19] xml2_1.3.3           httpuv_1.6.6         assertthat_0.2.1    \n [22] gargle_1.2.1         xfun_0.34            hms_1.1.2           \n [25] bayesplot_1.9.0      evaluate_0.18        promises_1.2.0.1    \n [28] fansi_1.0.3          dbplyr_2.2.1         readxl_1.4.1        \n [31] igraph_1.3.5         DBI_1.1.3            htmlwidgets_1.5.4   \n [34] tensorA_0.36.2       googledrive_2.0.0    stats4_4.2.0        \n [37] ellipsis_0.3.2       crosstalk_1.2.0      backports_1.4.1     \n [40] V8_4.2.1             survey_4.1-1         insight_0.18.6      \n [43] markdown_1.3         RcppParallel_5.1.5   vctrs_0.5.0         \n [46] sjlabelled_1.2.0     abind_1.4-5          cachem_1.0.6        \n [49] withr_2.5.0          drgee_1.1.10         checkmate_2.1.0     \n [52] emmeans_1.8.2        xts_0.12.2           prettyunits_1.1.1   \n [55] svglite_2.1.0        crayon_1.5.2         labeling_0.4.2      \n [58] SuppDists_1.1-9.7    pkgconfig_2.0.3      nlme_3.1-158        \n [61] pkgload_1.3.1        nnet_7.3-18          globals_0.16.1      \n [64] rlang_1.0.6          lifecycle_1.0.3      miniUI_0.1.1.1      \n [67] nleqslv_3.3.3        colourpicker_1.2.0   sandwich_3.0-2      \n [70] mathjaxr_1.6-0       modelr_0.1.9         cellranger_1.1.0    \n [73] distributional_0.3.1 rprojroot_2.0.3      matrixStats_0.62.0  \n [76] datawizard_0.6.3     loo_2.5.1            carData_3.0-5       \n [79] boot_1.3-28          zoo_1.8-11           reprex_2.0.2        \n [82] base64enc_0.1-3      gamm4_0.2-6          ggridges_0.5.4      \n [85] processx_3.8.0       googlesheets4_1.0.1  viridisLite_0.4.1   \n [88] parallelly_1.32.1    shinystan_2.6.0      rstatix_0.7.0       \n [91] ggsignif_0.6.4       scales_1.2.1         memoise_2.0.1       \n [94] magrittr_2.0.3       plyr_1.8.7           threejs_0.3.3       \n [97] compiler_4.2.0       rstantools_2.2.0     snakecase_0.11.0    \n[100] cli_3.4.1            urlchecker_1.0.1     listenv_0.8.0       \n[103] ps_1.7.2             Brobdingnag_1.2-9    Formula_1.2-4       \n[106] MASS_7.3-58.1        mgcv_1.8-40          tidyselect_1.2.0    \n[109] stringi_1.7.8        projpred_2.2.1       mitools_2.4         \n[112] yaml_2.3.6           bridgesampling_1.1-2 grid_4.2.0          \n[115] sass_0.4.2           ggdag_0.2.7          tools_4.2.0         \n[118] parallel_4.2.0       rstudioapi_0.14      foreign_0.8-83      \n[121] medflex_0.6-7        gridExtra_2.3        posterior_1.3.1     \n[124] farver_2.1.1         digest_0.6.30        simex_1.8           \n[127] shiny_1.7.3          operator.tools_1.6.3 metafor_3.8-1       \n[130] car_3.1-1            broom_1.0.1          later_1.3.0         \n[133] httr_1.4.4           MetaUtility_2.1.2    colorspace_2.0-3    \n[136] rvest_1.0.3          fs_1.5.2             expm_0.999-6        \n[139] renv_0.16.0          shinythemes_1.2.0    sessioninfo_1.2.2   \n[142] systemfonts_1.0.4    xtable_1.8-4         jsonlite_1.8.3      \n[145] nloptr_2.0.3         tidygraph_1.2.2      R6_2.5.1            \n[148] broom.mixed_0.2.9.4  profvis_0.3.7        pillar_1.8.1        \n[151] htmltools_0.5.3      mime_0.12            glue_1.6.2          \n[154] fastmap_1.1.0        minqa_1.2.5          DT_0.26             \n[157] codetools_0.2-18     furrr_0.3.1          pkgbuild_1.3.1      \n[160] mvtnorm_1.1-3        utf8_1.2.2           lattice_0.20-45     \n[163] numDeriv_2016.8-1.1  curl_4.3.3           gtools_3.9.3        \n[166] shinyjs_2.1.0        survival_3.4-0       rmarkdown_2.17      \n[169] repr_1.1.4           munsell_0.5.0        broom.helpers_1.9.0 \n[172] haven_2.5.1          reshape2_1.4.4       gtable_0.3.1        \n[175] bayestestR_0.13.0"
  },
  {
    "objectID": "posts/trust-science/trust-science.html",
    "href": "posts/trust-science/trust-science.html",
    "title": "Institutional Trust in New Zealand Pre/Post COVID-19 Pandemic",
    "section": "",
    "text": "We investigate changes to institutional trust among New Zealanders from the pre-pandemic period in 2019 to 2022.\nThe New Zealand Attitudes and Values Study uses a two-item scale to measure Trust in Science\n\n“I have a high degree of confidence in the scientific community.”(Nisbet, Cooper, and Garrett 2015)\n“Our society places too much emphasis on science.”(reverse coded)\n\nWe average these scores to form a single score (Hartman et al. 2017). These items were introduced in NZAVS Wave 11 (2019 - 2020).\nPrevious research using a propensity score design reported on changes in Trust in Science during the first three weeks of New Zealand’s COVID lockdown in March and April 2020 (Sibley et al. 2020).\nCOVID-19 Government response (Marques et al. 2022)\n\n“I trust the Government to make sensible decisions about how to best manage COVID-19 in New Zealand.”\n“The New Zealand government response to COVID-19.”\n\nTrust in politicians (Sibley et al. 2020)\n\n“Politicians in New Zealand can generally be trusted.”\n\nInstitutional trust in police (Tyler 2005)\n\n“People’s basic rights are well protected by the New Zealand Police.”\n“There are many things about the New Zealand Police and its policies that need to be changed.”\n“The New Zealand Police care about the well-being of everyone they deal with.”\n\nGeneral tendency to believe in conspiracies(Lantian et al. 2016)\n\n“I think that the official version of major world events given by authorities often hides the truth.”\n\n\n\n\n\nShow the code\n# read data\ndat &lt;- arrow::read_parquet(pull_path)\n\n# sometimes arrow objects give me trouble\ndat &lt;- as.data.frame(dat)\n\n\n# create covid timeline variables, select waves of interest. \ndt &lt;- dat |&gt;\n  data.frame() |&gt;\n# create covid timeline \n mutate(covid_condition = as.factor(ifelse(\n    TSCORE &lt; 3922,\n    \"pre_covid\",\n    ifelse(TSCORE &gt;= 3922 &\n             TSCORE &lt;= 3954, \"lockdown\",\n           \"post_lockdown\")\n  ))) |&gt; \n  mutate(covid_condition = factor(covid_condition, levels = c(\"pre_covid\", \"lockdown\", \"post_lockdown\"))) |&gt; # order levels\n  # select waves\n  dplyr::filter(Wave == 2019| Wave == 2020| Wave == 2021) |&gt;\n    dplyr::filter(\n      (Wave == 2019  &\n         YearMeasured  == 1 & !is.na(covid_condition)) |\n      (Wave == 2020) |\n      (Wave == 2021)) |&gt;  \n  group_by(Id) |&gt; \n  # inclusion criteria, all those who participated in 2019\n  dplyr::mutate(org2019 = ifelse(Wave == 2019 &\n                                   YearMeasured == 1, 1, 0)) |&gt;  # creating an indicator for the first wave\n  dplyr::mutate(hold19 = mean(org2019, na.rm = TRUE)) |&gt;  # Hack\n  dplyr::filter(hold19 &gt; 0) |&gt; # hack to enable repeat of baselin\n  fill(w_GendAgeEuro, .direction = \"down\") |&gt; # weights are all for 2018. Fill if missing\n  ungroup() |&gt;\n  droplevels() |&gt;\n  mutate(time = as.numeric(Wave) - 1) |&gt;\n  arrange(Id, time) |&gt;\n  select(\n    Id,\n    covid_condition,\n    YearMeasured,\n    COVID19.Timeline,\n    w_GendAgeEuro, # survey weights for PATT\n    time,\n    TSCORE,\n    Wave,\n    Partner,\n    Euro,\n    EthCat,\n    GenCohort,\n    # Gender3,\n    Male,\n    SampleFrame,\n    NZSEI13,\n    NZDep2018,\n    Rural_GCH2018,\n    REGC_2022,\n    CONSCIENTIOUSNESS,\n    OPENNESS,\n    HONESTY_HUMILITY,\n    EXTRAVERSION,\n    NEUROTICISM,\n    AGREEABLENESS,\n    edu_n,\n    Employed,\n    BornNZ,\n    Pol.Orient,\n    Pol.Wing,\n    Parent,\n    Relid,\n    SDO,\n    RWA,\n    ConspiracyBeliefs,\n    SCIENCE.TRUST,\n    POLICE.TRUST,\n    COVID.TrustGovtResponse,\n    Pol.PoliticianTrust#,\n  # ScienceTrust01, # individual item\n  # ScienceTrust02r  # individual item\n  ) |&gt; \n  rename(\n  Conspiracy_Beliefs  = ConspiracyBeliefs,\n  Trust_in_Science =  SCIENCE.TRUST,\n  Trust_in_Politicians = Pol.PoliticianTrust,\n  Trust_in_Police = POLICE.TRUST,\n  Trust_in_Govt_Covid_Response = COVID.TrustGovtResponse, \n  ) |&gt; \n  droplevels() |&gt; \n  arrange(Id,Wave)\n\n\n\n\nShow the code\n# this code creates a table\n# function to make tables simple         \n# simplify\nmy.render.cont &lt;- function(x) {\n  with(stats.apply.rounding(stats.default(x), digits=3), c(\"\",\n                                                           \"Mean (SD)\"=sprintf(\"%s (&plusmn; %s)\", MEAN, SD)))\n}\n\nmy.render.cat &lt;- function(x) {\n  c(\"\", sapply(stats.default(x), function(y) with(y,\n                                                  sprintf(\"%d (%0.0f %%)\", FREQ, PCT))))\n}\n\n\n# select only 2019-2021\ndt_19 &lt;-dt |&gt; \n  dplyr::filter(Wave == 2019)\n\n\ntab_19_trust &lt;- table1::table1(\n  ~ Trust_in_Science +\n    Trust_in_Politicians +\n    Trust_in_Police +\n    Conspiracy_Beliefs| covid_condition,\n  data = dt_19,\n  overall = FALSE,\n  render.continuous = my.render.cont,\n  render.categorical = my.render.cat\n)\n\n# needed for markdown tables\ntab_19_trust &lt;- data.frame( tab_19_trust )\n\ntab_19_trust &lt;- tab_19_trust |&gt; \n    rename(\"Forms of Institutional Trust\" = X.)\n\n# show\ntab_19_trust |&gt;\n  kbl(format = \"markdown\", booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nForms of Institutional Trust\npre_covid\nlockdown\npost_lockdown\n\n\n\n\n\n(N=29812)\n(N=3511)\n(N=9358)\n\n\nTrust_in_Science\n\n\n\n\n\nMean (SD)\n5.36 (± 1.28)\n5.66 (± 1.23)\n5.55 (± 1.27)\n\n\nMissing\n289 (1.0%)\n16 (0.5%)\n70 (0.7%)\n\n\nTrust_in_Politicians\n\n\n\n\n\nMean (SD)\n3.72 (± 1.44)\n4.00 (± 1.48)\n3.78 (± 1.48)\n\n\nMissing\n685 (2.3%)\n25 (0.7%)\n143 (1.5%)\n\n\nTrust_in_Police\n\n\n\n\n\nMean (SD)\n4.61 (± 1.23)\n4.60 (± 1.34)\n4.50 (± 1.33)\n\n\nMissing\n12 (0.0%)\n0 (0%)\n3 (0.0%)\n\n\nConspiracy_Beliefs\n\n\n\n\n\nMean (SD)\n4.38 (± 1.60)\n4.29 (± 1.68)\n4.31 (± 1.69)\n\n\nMissing\n940 (3.2%)\n43 (1.2%)\n214 (2.3%)\n\n\n\n\n\nHere is a graph of the same.\n\n\nShow the code\ndt_temp_19 &lt;- dt_19 |&gt; select(\n  covid_condition,\n  Trust_in_Science,\n  Trust_in_Politicians,\n  Trust_in_Police,\n  Conspiracy_Beliefs\n)\n\n\n# boxplot dataframe\ndt_long_19 &lt;- pivot_longer(\n  dt_temp_19,\n  cols = -c(\"covid_condition\"),\n  names_prefix = \"Trust_in_\",\n  values_to = \"Values\",\n  names_to = \"Attitudes\"\n) |&gt;\n  drop_na()\n\n\n# make graph\nplot_tab_19 &lt;- dt_long_19 |&gt;\n  ggplot2::ggplot(aes(covid_condition, Values, fill = Attitudes)) +\n  labs(title = \"Institutional Trust and Conspiracy Beliefs (1-7)\",\n       subtitle = \"NZAVS 2019/2020  (N = 42,681)\") +\n  geom_boxplot(size = .05, notch = T) +\n  scale_fill_okabe_ito() +\n  facet_grid (. ~ covid_condition, scales = \"free_x\", space = \"free_x\") +\n  theme(legend.position = \"none\") +\n  labs(x = \"Covid Condition\",\n       y = \"Trust response (1-7)\") +\n  theme_classic()\n\n# graph\nplot_tab_19\n\n\n\n\n\n\n\n\nFigure 1: Boxplot for Institutional Trust: NZAVS Waves During Covid: Years 2020\n\n\n\n\n\nThis table and graph compare the trust in science, police, and politicians across three different periods: pre-Covid, lockdown, and post-lockdown.\nWe observe:\n\nTrust in science increased during the lockdown period and remained higher in the post-lockdown period compared to the pre-Covid period.\nTrust in police remained relatively stable across all three periods, although the trend tracked downward after lockdown.\nTrust in politicians increased during the lockdown period. It decreased slightly in the post-lockdown period but remained higher than in the pre-Covid period.\nConspiracy Beliefs: the average mistrust of official versions of major world events given by authorities appear to decrease during lockdown but subsequently decrease.\n\nNotably, the central tendency may not always be the interesting statistic for understanding social change. There may be greater separation in response that is masked by overall average response. In future work, we will examine this point. For now, the trends suggest overall stability during 2019-2020, with increasing confidence in science.\n\n\n\nNext, we examine changes in institutional trust across two waves following the 2019/2020 NZAVS wave.\nTable:\n\n\nShow the code\n#|echo: false\n#|warning: false\n\n\n# this code creates a table\n# functions to make tables simple\n\nmy.render.cont &lt;- function(x) {\n  with(stats.apply.rounding(stats.default(x), digits=3), c(\"\",\n                                                           \"Mean (SD)\"=sprintf(\"%s (&plusmn; %s)\", MEAN, SD)))\n}\n\nmy.render.cat &lt;- function(x) {\n  c(\"\", sapply(stats.default(x), function(y) with(y,\n                                                  sprintf(\"%d (%0.0f %%)\", FREQ, PCT))))\n}\n\n# now the years \ntab_trust &lt;- table1::table1(\n  ~ Trust_in_Science +\n    Trust_in_Politicians +\n    Trust_in_Police + # not measured in 2019-20\n    Trust_in_Govt_Covid_Response + \n    Conspiracy_Beliefs| Wave,\n  data = dt,\n  overall = FALSE,\n  render.continuous = my.render.cont,\n  render.categorical = my.render.cat\n)\n\n\n# needed for markdown tables\ntab_trust &lt;- data.frame( tab_trust )\n\ntab_trust &lt;- tab_trust |&gt; \n    rename(\"Forms of Institutional Trust\" = X.)\n\n\n# graph\ntab_trust |&gt;\n  kbl(format = \"markdown\", booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nForms of Institutional Trust\nX2019\nX2020\nX2021\n\n\n\n\n\n(N=42681)\n(N=42681)\n(N=42681)\n\n\nTrust_in_Science\n\n\n\n\n\nMean (SD)\n5.43 (± 1.28)\n5.67 (± 1.24)\n5.70 (± 1.26)\n\n\nMissing\n375 (0.9%)\n9475 (22.2%)\n14231 (33.3%)\n\n\nTrust_in_Politicians\n\n\n\n\n\nMean (SD)\n3.76 (± 1.45)\n4.05 (± 1.49)\n3.92 (± 1.56)\n\n\nMissing\n853 (2.0%)\n10078 (23.6%)\n15406 (36.1%)\n\n\nTrust_in_Police\n\n\n\n\n\nMean (SD)\n4.58 (± 1.26)\n4.53 (± 1.26)\n4.43 (± 1.30)\n\n\nMissing\n15 (0.0%)\n9378 (22.0%)\n13770 (32.3%)\n\n\nTrust_in_Govt_Covid_Response\n\n\n\n\n\nMean (SD)\nNA (± NA)\n5.66 (± 1.55)\n4.79 (± 1.94)\n\n\nMissing\n42681 (100%)\n9620 (22.5%)\n15123 (35.4%)\n\n\nConspiracy_Beliefs\n\n\n\n\n\nMean (SD)\n4.36 (± 1.63)\n4.10 (± 1.68)\n4.02 (± 1.74)\n\n\nMissing\n1197 (2.8%)\n9676 (22.7%)\n15110 (35.4%)\n\n\n\n\n\nHere is a graph of the same.\n\n\nShow the code\n# transform data into long formate\ndt_temp &lt;- dt |&gt; select(\n  Wave,\n  Trust_in_Science,\n  Trust_in_Politicians,\n  Trust_in_Police,\n  Trust_in_Govt_Covid_Response, \n  Conspiracy_Beliefs\n)\n\n\n# boxplot dataframe\ndt_long &lt;- pivot_longer(\n  dt_temp,\n  cols = -c(\"Wave\"),\n  names_prefix = \"Trust_in_\",\n  values_to = \"Values\",\n  names_to = \"Attitudes\"\n) |&gt;\n  drop_na()\n\n\n# make graph\nplot_tab &lt;- dt_long |&gt;\n  ggplot2::ggplot(aes(Wave, Values, fill = Attitudes)) +\n  labs(title = \"Institutional Trust and Conspiracy Beliefs\",\n       subtitle = \"NZ 2019/21 to 2021/22 [N = 42,681 (at baseline)]\") +\n  geom_boxplot(size = .05, notch = T) +\n  scale_fill_okabe_ito() +\n  facet_grid (. ~ Wave, scales = \"free_x\", space = \"free_x\") +\n  theme(legend.position = \"none\") +\n  labs(y = \"NZAVS Wave (note: waves cross years)\") + \n  theme_classic()\n\n\nplot_tab\n\n\n\n\n\n\n\n\nFigure 2: Boxplot for Institutional Trust: NZAVS Waves 11-13 (years 2019-2022)\n\n\n\n\n\nDescriptive fndings.\nTrust in Science: The average trust score increased from 5.43 (±1.28) in 2019 to 5.67 (±1.24) in 2020 and to 5.70 (±1.26) in 2021. The number of missing values increased from 375 (0.9%) in 2019 to 9,475 (22.2%) in 2020 and further to 14,231 (33.3%) in 2021.\nTrust in Politicians: The average trust score increased from 3.76 (±1.45) in 2019 to 4.05 (±1.49) in 2020, then slightly decreased to 3.92 (±1.56) in 2021. The number of missing values increased from 853 (2.0%) in 2019 to 10,078 (23.6%) in 2020 and further to 15,406 (36.1%) in 2021.\nTrust in Police: The average trust score decreased from 4.58 (±1.26) in 2019 to 4.53 (±1.26) in 2020 and further to 4.43 (±1.30) in 2021. The number of missing values increased from 15 (0.0%) in 2019 to 9,378 (22.0%) in 2020 and further to 13,770 (32.3%) in 2021.\nTrust in Government’s COVID Response: This metric was not applicable in 2019. The average trust score was 5.66 (±1.55) in 2020 and decreased to 4.79 (±1.94) in 2021. The number of missing values was 42,681 (100%) in 2019, 9,620 (22.5%) in 2020, and 15,123 (35.4%) in 2021.\nConspiracy Beliefs: The average score decreased from 4.36 (±1.63) in 2019 to 4.10 (±1.68) in 2020 and further to 4.02 (±1.74) in 2021. The number of missing values increased from 1,197 (2.8%) in 2019 to 9,676 (22.7%) in 2020 and further to 15,110 (35.4%) in 2021.\nHow should we in interpret these findings? Missing data from non-response and panel attrition may bias estimates for the population. We must address bias from missing responses. We address this bias through multiple imputation."
  },
  {
    "objectID": "posts/trust-science/trust-science.html#conclusion",
    "href": "posts/trust-science/trust-science.html#conclusion",
    "title": "Exploring Institutional Trust in New Zealand Pre/Post COVID-19 Pandemic",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe NZAVS is a national probability panel study that has good coverage of the NZAVS population.\nIn New Zealand, average levels of confidence in science remained even as there is evidence for strong declines for average trust in the government’s pandemic response and evidence for declines in other forms of instititutial mistrust.\nIt is not sufficient to model the average responses because there appears to be both increasing and descreasing trajectories.\nOur next set of models will investigate these dynamics of change.\n\n\nInformation about the New Zealand Attitudes and Values Study.\nFor more information about the NZAVS see: here and here"
  },
  {
    "objectID": "posts/trust-science/trust-science.html#handling-missingness",
    "href": "posts/trust-science/trust-science.html#handling-missingness",
    "title": "Institutional Trust in New Zealand Pre/Post COVID-19 Pandemic",
    "section": "Handling missingness",
    "text": "Handling missingness\nTo handle missing data, we must model and predict missing responses. We attempt two types of missing data imputation. Both use machine learning. The first is the mlim package in R, which uses model tuning to optimise the prediction of missing values. The second is the mice package in R. It uses predictive mean matching (ppm) optimse the prediction of missing values. We find that the mice package/ppm performs better, and present theppm results here. We present the code for both approaches below.\n\n\nShow the code\nmc_vv &lt;- readRDS(here::here(push_mods, \"mc_vv\"))\n\n# transform data into long format for graph and table\ndt_temp_mice &lt;- mc_vv |&gt; select(\n  Wave,\n  Trust_in_Science,\n  Trust_in_Politicians,\n  Trust_in_Police,\n  Trust_in_Govt_Covid_Response, \n  Conspiracy_Beliefs\n)\n\n\n# boxplot dataframe\ndt_long_mice &lt;- pivot_longer(\n  dt_temp_mice,\n  cols = -c(\"Wave\"),\n  names_prefix = \"Trust_in_\",\n  values_to = \"Values\",\n  names_to = \"Attitudes\"\n) |&gt;\n  drop_na()\n\nlibrary(ggokabeito)\nplot_tab_mice &lt;- dt_long_mice |&gt;\n  ggplot2::ggplot(aes(Wave, Values, fill = Attitudes)) +\n  labs(title = \"Institutional Trust and Conspiracy Beliefs: Missingness Multiply-Imputed\",\n       subtitle = \"NZ 2019/21 to 2021/22 [N = 42,681 (at baseline)]\") +\n  geom_boxplot(size = .05, notch = T) +\n  scale_fill_okabe_ito() +\n  facet_grid (. ~ Wave, scales = \"free_x\", space = \"free_x\") +\n  theme(legend.position = \"none\") +\n  labs(y = \"NZAVS Wave (note: waves cross years)\") + \n  theme_classic()\n\n\nplot_tab_mice\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nmc_vv &lt;- readRDS(here::here(push_mods, \"mc_vv\"))\n# now the years \ntab_trust_mice &lt;- table1::table1(\n  ~ Trust_in_Science +\n    Trust_in_Politicians +\n    Trust_in_Police + # not measured in 2019-20\n    Trust_in_Govt_Covid_Response + \n    Conspiracy_Beliefs| Wave,\n  data = mc_vv,\n  overall = FALSE,\n  render.continuous = my.render.cont,\n  render.categorical = my.render.cat\n)\n\n\n\n# must be a data frame\ntab_trust_mice &lt;- data.frame(tab_trust_mice)\n\ntab_trust_mice &lt;- tab_trust_mice |&gt; \n    dplyr::rename(\"Forms of Institutional Trust\" = X.)\n\n# graph\ntab_trust_mice |&gt;\n  kbl(format = \"markdown\", booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nForms of Institutional Trust\nX2019\nX2020\nX2021\n\n\n\n\n\n(N=469491)\n(N=469491)\n(N=469491)\n\n\nTrust_in_Science\n\n\n\n\n\nMean (SD)\n5.43 (± 1.28)\n5.64 (± 1.25)\n5.65 (± 1.28)\n\n\nMissing\n375 (0.1%)\n9475 (2.0%)\n14231 (3.0%)\n\n\nTrust_in_Politicians\n\n\n\n\n\nMean (SD)\n3.76 (± 1.45)\n4.02 (± 1.50)\n3.85 (± 1.57)\n\n\nMissing\n853 (0.2%)\n10078 (2.1%)\n15406 (3.3%)\n\n\nTrust_in_Police\n\n\n\n\n\nMean (SD)\n4.58 (± 1.26)\n4.50 (± 1.27)\n4.37 (± 1.32)\n\n\nMissing\n15 (0.0%)\n9378 (2.0%)\n13770 (2.9%)\n\n\nTrust_in_Govt_Covid_Response\n\n\n\n\n\nMean (SD)\nNA (± NA)\n5.64 (± 1.56)\n4.74 (± 1.96)\n\n\nMissing\n469491 (100%)\n9620 (2.0%)\n15123 (3.2%)\n\n\nConspiracy_Beliefs\n\n\n\n\n\nMean (SD)\n4.36 (± 1.63)\n4.13 (± 1.68)\n4.06 (± 1.75)\n\n\nMissing\n1197 (0.3%)\n9676 (2.1%)\n15110 (3.2%)\n\n\n\n\n\nThe data consist of ten imputed datasets plus the original data with missing values. We will need to adjust for the uncertainities of multiple imputation using Rubin’s rule.\nAdditionally, we are now grouping pre and post responses together in the 2019 wave. So we are no longer identifying specific responses of to the COVID pandemic and response. To identify the specific effects of the COVID pandemic and response requires care. There are no contrasts from which to derive comparisons. That is, because all in the population were subject to the exposure, we cannot straightforwardly infer how people would have responded were they not exposed. We will return to this issue in future work.\nThese provisos aside, we find evidence for continued average confidence in science, with some evidence for a continued downward shift in trust for the NZ police.\nNext, we formally model change over time using generalised estimating equations (GEE), taking into account uncertainties from multiple imputation. We employ survey weights to recover population estimates.\n\nResults for average responses.\n\n\nTrust in science\n\n\nShow the code\n# read output for table\npooled_m_trust_in_science &lt;- readRDS( here::here(push_mods, \"pooled_m_trust_in_science\"))\n\nsummary( pooled_m_trust_in_science ) |&gt; \n  as.data.frame()|&gt; \n  kbl(format = \"markdown\", digits = 3, caption = \"Trust in Science by NZAVS Wave\")\n\n\n\nTrust in Science by NZAVS Wave\n\n\nterm\nestimate\nstd.error\nstatistic\ndf\np.value\n\n\n\n\n(Intercept)\n5.451\n0.007\n756.404\n62762.541\n0\n\n\nWave2020\n0.192\n0.006\n29.781\n176.552\n0\n\n\nWave2021\n0.215\n0.007\n29.572\n146.591\n0\n\n\n\n\n\n\n\nShow the code\n# read output for table\npooled_m_trust_in_politicians &lt;- readRDS( here::here(push_mods, \"pooled_m_trust_in_politicians\"))\n\n \nsummary( pooled_m_trust_in_politicians ) |&gt; \n  as.data.frame()|&gt; \n  kbl(format = \"markdown\", digits = 3,  caption = \"Trust in Politicians by NZAVS Wave\")\n\n\n\nTrust in Politicians by NZAVS Wave\n\n\nterm\nestimate\nstd.error\nstatistic\ndf\np.value\n\n\n\n\n(Intercept)\n3.736\n0.008\n441.327\n14871.025\n0\n\n\nWave2020\n0.251\n0.009\n28.251\n93.102\n0\n\n\nWave2021\n0.080\n0.009\n8.803\n259.975\n0\n\n\n\n\n\n\n\nShow the code\n# read output for table\npooled_m_trust_in_police &lt;- readRDS( here::here(push_mods, \"pooled_m_trust_in_police\"))\n\n \nsummary( pooled_m_trust_in_police ) |&gt; \n  as.data.frame()|&gt; \n  kbl(format = \"markdown\", digits = 3,  caption = \"Trust in Police by NZAVS Wave\")\n\n\n\nTrust in Police by NZAVS Wave\n\n\nterm\nestimate\nstd.error\nstatistic\ndf\np.value\n\n\n\n\n(Intercept)\n4.539\n0.008\n574.900\n103491.441\n0\n\n\nWave2020\n-0.110\n0.007\n-16.752\n111.240\n0\n\n\nWave2021\n-0.247\n0.008\n-31.849\n133.079\n0\n\n\n\n\n\n\n\nShow the code\n# read output for table\npooled_m_trust_in_gov_covid &lt;- readRDS( here::here(push_mods, \"pooled_m_trust_in_gov_covid\"))\n\nsummary( pooled_m_trust_in_gov_covid ) |&gt; \n  as.data.frame()|&gt; \n  kbl(format = \"markdown\", digits = 3, caption = \"Trust in Covid Governemnt Response by NZAVS Wave\")\n\n\n\nTrust in Science by NZAVS Wave\n\n\nterm\nestimate\nstd.error\nstatistic\ndf\np.value\n\n\n\n\n(Intercept)\n5.614\n0.011\n523.237\n103.496\n0\n\n\nWave2021\n-0.903\n0.011\n-81.429\n67.518\n0\n\n\n\n\n\n\n\nShow the code\n# read output for table\npooled_m_conspiracy_beliefs &lt;- readRDS(  here::here(push_mods, \"pooled_m_conspiracy_beliefs\"))\n\nsummary(pooled_m_conspiracy_beliefs) |&gt; \n  as.data.frame()|&gt; \n  kbl(format = \"markdown\", digits = 3, caption =  \"Conspiracy Beliefs by NZAVS Wave\")\n\n\n\nConspiracy Beliefs by NZAVS Wave\n\n\nterm\nestimate\nstd.error\nstatistic\ndf\np.value\n\n\n\n\n(Intercept)\n4.362\n0.009\n464.975\n4101.840\n0\n\n\nWave2020\n-0.251\n0.012\n-20.768\n49.163\n0\n\n\nWave2021\n-0.308\n0.013\n-23.368\n48.228\n0\n\n\n\n\n\nThe results reflect findings in the descriptiove tables.\n\nTrust in Science by NZAVS Wave:\n\nFrom 2019 to 2020, trust in science reliably increased (estimate = 0.192, p &lt; 0.001).\nFrom 2019 to 2021, trust in science also reliably increased (estimate = 0.215, p &lt; 0.001).\n\nThere is no evidence for a downward trend in average Trust in Science as of 2021.\n\n\nTrust in Politicians by NZAVS Wave:\n\nFrom 2019 to 2020, the increase in trust in politicians was reliable (estimate = 0.251, p &lt; 0.001).\nFrom 2019 to 2021, the increase in trust in politicians was also reliable (estimate = 0.080, p &lt; 0.001).\n\nComparisons here are with the baseline wave, comparing 2019 and 2021 we find evidence for regression to the baseline wave. Whereas trust in politicians increased during the initial COVID-19 attack and response, gains to average trust appear to have been dropping.\n\n\nTrust in Police by NZAVS Wave:\n\nFrom 2019 to 2020, the decrease in trust in police was reliable (estimate = -0.110, p &lt; 0.001).\nFrom 2019 to 2021, the decrease in trust in police was also reliable (estimate = -0.247, p &lt; 0.001).\n\nHere we find evidence for declining Trust in the NZ police. Notably, however, overall levels of Trust in the NZ police remain high.\n\n\nTrust in Government COVID Response by NZAVS Wave (only two waves):\n\nFrom 2019 to 2021, the decrease in trust in the NZ government’s COVID response was reliable (estimate = -0.903, p &lt; 0.001). This represents a major drop in confidence. Notably, this drop in confidence for the NZ government’s COVID response has not considerably affected attitudes to science.\n\n\n\nConspiracy Beliefs:\n\nFrom 2019 to 2020, the decrease in conspiracy beliefs was reliable (estimate = -0.251, p &lt; 0.001).\nFrom 2019 to 2021, the decrease in conspiracy beliefs was also reliable (estimate = -0.308, p &lt; 0.001).\n\nOn average, we find that conspiracy beliefs are falling. However, this evidence is based on the assumptions that the model we have used impute missing conspiracy beliefs is adequate. It is possible that real change in conspiracy beliefs, and indeed for all imputed variables differs from what we have recovered in the imputation model.\n\n\n\nSummary\nThe results suggest a reliable increase in trust in science from 2019 to 2020, and that this shift has remained constant. In contrast, changes in trust in politicians, trust in police, trust in the government’s COVID response, across the waves were generally unreliable. Evidence suggests that average conspiracy beliefs may have declined.\nThe preliminary findings merit further research.\nFirstly, multiple imputation models rely on assumptions. These assumptions must be tested.\nSecondly, when a population becomes more polarised, the average response may be misleading, potentially indicating no change. We must investigate change at the margins of reponse, not merely at the average response.\nThirdly, we need not assume that the items model a univariate latent construct. We might instead model items from the scales individually, as suggested by VanderWeele (2022).\nFourth, we cannot know how trust in science would have changed had there been no Pandemic because there is no contrast condition.\nIn the near future, that address these challenges. Stay tuned!\n\n\nInformation about the New Zealand Attitudes and Values Study.\nFor more information about the NZAVS see: here and here"
  },
  {
    "objectID": "posts/g-computation/g-computation.html",
    "href": "posts/g-computation/g-computation.html",
    "title": "G-computation in NZAVS Studies",
    "section": "",
    "text": "Suppose we want to infer whether a binary exposure has a causal effect. We must answer three questions:\n\nWhat would happen with exposure?\nWhat would happen without exposure?\nDo these potential outcomes differ?\n\nConsider a binary exposure \\(A\\) with two levels, \\(A = 0\\) and \\(A = 1\\) and a continuous outcome \\(Y\\). Estimating the causal effect of \\(A\\) on outcome \\(Y\\) requires contrasting two counterfactual states of the world: the state \\(Y^{a=1}\\) when, hypothetically, \\(A\\) is set to \\(1\\) and the state \\(Y^{a=0}\\) when, hypothetically, \\(A\\) is set to \\(0\\). We say that \\(A\\) affects \\(Y\\) when the quantities \\(Y^{a=1} - Y^{a=0} \\neq 0\\) (Hernan and Robins 2023).\n\n\nAt any given time, for any individual, at most only one level of the exposure \\(A\\) may be realised. That is, \\(Y^{a=1}\\) and \\(Y^{a=0}\\) are never simultaneously observed for any individual. As such, individual-level causal effects are not typically identifiable in the data. This is referred to as “the fundamental problem of causal inference” (Rubin 1976; Gelman, Hill, and Vehtari 2020). \\(Y^{a=1}\\) and \\(Y^{a=0}\\) are therefore called “potential” or “counterfactual” outcomes.\nAlthough we generally cannot observe individual causal effects, when certain assumptions are satisfied, we may identify the average or marginal causal effect at the population level. We say there is an average or marginal causal effect if the difference of the means of those who are exposed and not exposed does not equal zero: \\(E(Y^{a=1}) - E(Y^{a=0})\\neq 0\\). Because the difference of the means is equivalent to the mean of the differences, we may equivalently say there is a marginal causal effect if \\(E(Y^{a=1} - Y^{a=0})\\neq 0\\) (Hernan and Robins 2023).\nTo ensure valid inference, the potential outcomes must be conditionally independent of the exposure:\n\\[Y^a \\perp\\!\\!\\!\\perp A|L\\]\nOutside of controlled experiments, we cannot typically ensure this conditional independence. For this reason, we use sensitivity analysis, such as the E-value (VanderWeele, Mathur, and Chen 2020)."
  },
  {
    "objectID": "posts/g-computation/g-computation.html#g-computation-or-regression-standardisation",
    "href": "posts/g-computation/g-computation.html#g-computation-or-regression-standardisation",
    "title": "G-computation in NZAVS Studies",
    "section": "G-Computation (or Regression Standardisation)",
    "text": "G-Computation (or Regression Standardisation)\nTo consistently estimate a causal association, we must infer the average outcomes for the entire population, were it subject to different levels of the exposure variable \\(A = a\\) and \\(A=a^*\\). The average treatment effect (ATE) can be expressed as:\n\\[ATE = E[Y^{a^*}] - E[Y^a] = \\sum_l E[Y|A=a^*, L=l]\\Pr[L=l] - \\sum_l E[Y|A=a, L=l]\\Pr[L=l]\\]\nHowever, we need not estimate \\(\\Pr(L = l)\\) directly. Instead, we can obtain the weighted mean for the distribution of the confounders in the data by taking the double expectation: (Hernan and Robins 2023, 166).\n\\[ATE = E[E(Y|A = a, \\boldsymbol{L}) - E(Y|A = a^*, \\boldsymbol{L})]\\]\nWe use the stdReg package in R to obtain marginal contrasts for the expected outcomes for the entire population (Sjölander 2016)."
  },
  {
    "objectID": "posts/g-computation/g-computation.html#steps-for-g-computation",
    "href": "posts/g-computation/g-computation.html#steps-for-g-computation",
    "title": "G-computation in NZAVS Studies",
    "section": "Steps for G-Computation",
    "text": "Steps for G-Computation\n\nFit a regression for the outcome on the exposure \\(A_{t0}\\) and baseline covariates \\(\\boldsymbol{L} = (L_1, L_2,L_3 \\dots L_n)\\). To avoid making unjustified linearity assumptions, model the relationship between the exposure and each of the potential outcomes of interest using a cubic spline. Include in the set of baseline confounders \\(\\boldsymbol{L}\\), the baseline measure of the exposure as well as the baseline responses:\n\\[\\{A_{t-1}, \\boldsymbol{Y_{t-1}} = (Y_{1, t-1}, Y_{2, t-1}, Y_{3, t-1}\\dots Y_{n, t-1})\\} \\subset \\boldsymbol{L}\\]\nThis provides\n\\[E(Y|A, \\boldsymbol{L})\\]\nUse the model from step 1 to predict the values of a potential outcome \\(Y^{a}\\) by setting the exposure to the value \\(A = a\\).\nThis provides\n\\[\\hat{E}(Y|A = a, \\boldsymbol{L})\\]\nUse the model from step 1 to predict the values of a different potential outcome \\(Y^{a*}\\) by setting the exposure to a different value of \\(A = a^{\\star}\\).\nThis provides\n\\[\\hat{E}(Y|A = a^*, \\boldsymbol{L})\\]\nObtain the focal contrast as the expected difference in the average outcomes when exposure is at levels \\(a*\\) and \\(a\\). For continuous outcomes, calculate the mean of \\(Y^a\\) and the mean of \\(Y^{a*}\\) and then find their difference. This provides:\n\\[\\hat{ATE} = \\hat{E}[\\hat{E}(Y|A = a, \\boldsymbol{L}) - \\hat{E}(Y|A = a^*, \\boldsymbol{L})]\\]\nFor binary outcomes, calculate the causal risk ratio in moving between different levels of A. When binary outcomes are more common than 10%, use a log-normal model to calculate a causal rate ratio (VanderWeele, Mathur, and Chen 2020).\nThe stdReg package in R calculates standard errors using the Delta method, from which we construct confidence intervals under asymptotic assumptions (Sjölander 2016). Additionally, we pool uncertainty arising from the multiple imputation procedure by employing Rubin’s Rules."
  },
  {
    "objectID": "posts/g-computation/g-computation.html#g-computation-or-regression-standardisation-1",
    "href": "posts/g-computation/g-computation.html#g-computation-or-regression-standardisation-1",
    "title": "G-computation in NZAVS Studies",
    "section": "G-Computation (or Regression Standardisation)",
    "text": "G-Computation (or Regression Standardisation)\nTo consistently estimate a causal association, we must infer the average outcomes for the entire population, were it subject to different levels of the exposure variable \\(A = a\\) and \\(A=a^*\\). The average treatment effect (ATE) can be expressed as:\n\\[ATE = E[Y^{a^*}] - E[Y^a] = \\sum_l E[Y|A=a^*, L=l]\\Pr[L=l] - \\sum_l E[Y|A=a, L=l]\\Pr[L=l]\\]\nHowever, we need not estimate \\(\\Pr(L = l)\\) directly. Instead, we can obtain the weighted mean for the distribution of the confounders in the data by taking the double expectation: (Hernan and Robins 2023, 166).\n\\[ATE = E[E(Y|A = a, \\boldsymbol{L}) - E(Y|A = a^*, \\boldsymbol{L})]\\]\nWe use the stdReg package in R to obtain marginal contrasts for the expected outcomes for the entire population (Sjölander 2016)."
  },
  {
    "objectID": "posts/g-computation/g-computation.html#applications",
    "href": "posts/g-computation/g-computation.html#applications",
    "title": "G-computation in NZAVS Studies",
    "section": "Applications",
    "text": "Applications\nSee upcoming “Outcome-wide science” reports for illustrations of how we apply G-computation to NZAVS studies.\n\nAcknowledgements\nWe are grateful to Arvid Sjölander for his help in modifying his stdReg package in R to enable G-computation with multiply-imputed datasets.\nFor a simple visual guide to G-computation see Kat Hoffman’s blog"
  },
  {
    "objectID": "posts/g-computation/g-computation.html#causal-inference",
    "href": "posts/g-computation/g-computation.html#causal-inference",
    "title": "G-computation in NZAVS Studies",
    "section": "",
    "text": "Suppose we want to infer whether a binary exposure has a causal effect. We must answer three questions:\n\nWhat would happen with exposure?\nWhat would happen without exposure?\nDo these potential outcomes differ?\n\nConsider a binary exposure \\(A\\) with two levels, \\(A = 0\\) and \\(A = 1\\) and a continuous outcome \\(Y\\). Estimating the causal effect of \\(A\\) on outcome \\(Y\\) requires contrasting two counterfactual states of the world: the state \\(Y^{a=1}\\) when, hypothetically, \\(A\\) is set to \\(1\\) and the state \\(Y^{a=0}\\) when, hypothetically, \\(A\\) is set to \\(0\\). We say that \\(A\\) affects \\(Y\\) when the quantities \\(Y^{a=1} - Y^{a=0} \\neq 0\\) (Hernan and Robins 2023).\n\n\nAt any given time, for any individual, at most only one level of the exposure \\(A\\) may be realised. That is, \\(Y^{a=1}\\) and \\(Y^{a=0}\\) are never simultaneously observed for any individual. As such, individual-level causal effects are not typically identifiable in the data. This is referred to as “the fundamental problem of causal inference” (Rubin 1976; Gelman, Hill, and Vehtari 2020). \\(Y^{a=1}\\) and \\(Y^{a=0}\\) are therefore called “potential” or “counterfactual” outcomes.\nAlthough we generally cannot observe individual causal effects, when certain assumptions are satisfied, we may identify the average or marginal causal effect at the population level. We say there is an average or marginal causal effect if the difference of the means of those who are exposed and not exposed does not equal zero: \\(E(Y^{a=1}) - E(Y^{a=0})\\neq 0\\). Because the difference of the means is equivalent to the mean of the differences, we may equivalently say there is a marginal causal effect if \\(E(Y^{a=1} - Y^{a=0})\\neq 0\\) (Hernan and Robins 2023).\nTo ensure valid inference, the potential outcomes must be conditionally independent of the exposure:\n\\[Y^a \\perp\\!\\!\\!\\perp A|L\\]\nOutside of controlled experiments, we cannot typically ensure this conditional independence. For this reason, we use sensitivity analysis, such as the E-value (VanderWeele, Mathur, and Chen 2020)."
  },
  {
    "objectID": "posts/g-computation/g-computation.html#g-computation",
    "href": "posts/g-computation/g-computation.html#g-computation",
    "title": "G-computation in NZAVS Studies",
    "section": "G-Computation",
    "text": "G-Computation\n\nWhat is G-Computation?\nG-computation, sometimes called “regression standardisation” is a non-parametric method for estimating causal effects from observational data in the presence of confounding variables. It was introduced by James Robins in 1986 and is based on the potential outcomes framework. G-computation allows for estimating the causal effects of time-varying treatments and can handle complex treatment regimens and effect modification.\n\n\nHow Does G-Computation Work?\nTo consistently estimate a causal association from statistical associations in the data, we must infer the average outcomes for the entire population were it subject to different levels of the exposure variable \\(A = a\\) and \\(A=a^*\\). The average treatment effect (ATE) can be expressed as:\n\\[ATE = E[Y^{a^*}] - E[Y^a] = \\sum_l E[Y|A=a^*, L=l]\\Pr[L=l] - \\sum_l E[Y|A=a, L=l]\\Pr[L=l]\\]\nHowever, we need not estimate \\(\\Pr(L = l)\\) directly. Instead, we can obtain the weighted mean for the distribution of the confounders in the data by taking the double expectation: (Hernan and Robins 2023, 166).\n\\[ATE = E[E(Y|A = a, \\boldsymbol{L}) - E(Y|A = a^*, \\boldsymbol{L})]\\]\nStep 1. Fit a regression for the outcome on the exposure \\(A_{t0}\\) and baseline covariates \\(\\boldsymbol{L} = (L_1, L_2,L_3 \\dots L_n)\\). To avoid making unjustified linearity assumptions, model the relationship between the exposure and each of the potential outcomes of interest using a cubic spline. Include in the set of baseline confounders \\(\\boldsymbol{L}\\), the baseline measure of the exposure as well as the baseline responses:\n\\[\\{A_{t-1}, \\boldsymbol{Y_{t-1}} = (Y_{1, t-1}, Y_{2, t-1}, Y_{3, t-1}\\dots Y_{n, t-1})\\} \\subset \\boldsymbol{L}\\]\nThis provides\n\\[E(Y|A, \\boldsymbol{L})\\]\nStep 2. Use the model from step 1 to predict the values of a potential outcome \\(Y^{a}\\) by setting the exposure to the value \\(A = a\\).\nThis provides\n\\[\\hat{E}(Y|A = a, \\boldsymbol{L})\\]\nStep 3. Use the model from step 1 to predict the values of a different potential outcome \\(Y^{a*}\\) by setting the exposure to a different value of \\(A = a^{\\star}\\).\nThis provides\n\\[\\hat{E}(Y|A = a^*, \\boldsymbol{L})\\]\nStep 4. Obtain the focal contrast as the expected difference in the average outcomes when exposure is at levels \\(a*\\) and \\(a\\). For continuous outcomes, calculate the mean of \\(Y^a\\) and the mean of \\(Y^{a*}\\) and then find their difference. This provides:\n\\[\\hat{ATE} = \\hat{E}[\\hat{E}(Y|A = a, \\boldsymbol{L}) - \\hat{E}(Y|A = a^*, \\boldsymbol{L})]\\]\nStep 5. For binary outcomes, calculate the causal risk ratio in moving between different levels of A. When binary outcomes are more common than 10%, use a log-normal model to calculate a causal rate ratio (VanderWeele, Mathur, and Chen 2020).\nStep 6. The stdReg package in R calculates standard errors using the Delta method, from which we construct confidence intervals under asymptotic assumptions (Sjölander 2016). Additionally, we pool uncertainty arising from the multiple imputation procedure by employing Rubin’s Rules.\nStep 7. Finally, we perform sensitivity analyses to assess the sensitivity of the causal effect estimates to modelling assumptions."
  },
  {
    "objectID": "posts/g-computation/g-computation.html#what-are-the-assumptions-of-g-computation",
    "href": "posts/g-computation/g-computation.html#what-are-the-assumptions-of-g-computation",
    "title": "G-computation in NZAVS Studies",
    "section": "What are the assumptions of g-computation?",
    "text": "What are the assumptions of g-computation?\n\nOutcome Model Misspecification: G-computation’s performance depends on the correct specification of the outcome model. If the model is misspecified, g-computation can produce biased estimates of the ATE.\nConfounding: G-computation relies on the assumption that there are no unmeasured confounders. If this assumption is violated, the estimates can be biased."
  },
  {
    "objectID": "posts/iptw/iptw.html",
    "href": "posts/iptw/iptw.html",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "",
    "text": "Inverse Probability of Treatment Weighting (IPTW) is a method for estimating causal effects from observational data, using propensity scores to balance covariates between treated and untreated groups. This creates a pseudo-population where the probability of treatment assignment is independent of the observed covariates (gender, in our example below). Similar to G-computation, the method helps to estimate causal effects more accurately.\nHere, we consider IPTW in a setting where we wish to estimate the Average Treatment Effect (ATE)."
  },
  {
    "objectID": "posts/iptw/iptw.html#what-is-inverse-probability-of-treatment-weighting-iptw",
    "href": "posts/iptw/iptw.html#what-is-inverse-probability-of-treatment-weighting-iptw",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "",
    "text": "Inverse Probability of Treatment Weighting (IPTW) is a method for estimating causal effects from observational data, using propensity scores to balance covariates between treated and untreated groups. This creates a pseudo-population where the probability of treatment assignment is independent of the observed covariates (gender, in our example below). Similar to G-computation, the method helps to estimate causal effects more accurately.\nHere, we consider IPTW in a setting where we wish to estimate the Average Treatment Effect (ATE)."
  },
  {
    "objectID": "posts/iptw/iptw.html#the-role-of-bias-in-observational-data-an-example",
    "href": "posts/iptw/iptw.html#the-role-of-bias-in-observational-data-an-example",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "The Role of Bias in Observational Data: an example",
    "text": "The Role of Bias in Observational Data: an example\nConsider an observational dataset with measures for gender (L), frequency of doctor’s visits (our treatment A), and heart attack incidence (our outcome Y).\nSuppose:\n\nThe 10-year incidence risk of heart attacks is p for females.\nThe risk for males is 2p (twice as high).\nDoctor visits reduce the risk of heart attacks by 0.2p.\nMales are twice as less likely to visit doctors than females.\n\nThus, in our sample of 1,000 individuals:\n500 are males (50% of 1,000) 500 are females (50% of 1,000)\nThe overall risk R_sample in the sample can be calculated as the weighted sum of the risks in males and females:\nR_sample = 0.5 * 2p + 0.5 * p = 1.5p\nGiven that the gender proportions are balanced in our sample, R_sample should also represent the true risk\nR_population in the population: R_population = R_sample = 1.5p\nSo far, so good. However let us also supppose:\n\nDoctor’s visits (the treatment) reduce the risk of a heart attack by 0.25p.\nMales are 2x less likely to visit doctors than females.\n\nUnder these assumptions, the causal effect of treatment on the outcome will be biased.\nTo see this, let’s suppose the baseline risk for females and males are as follows: females is 0.2. Because males are 2x more likely to have heart attacks, the baseline risk for males is 0.4.\nNow, let’s calculate the treatment effect. If a female visits a doctor, her risk is reduced by 0.25p, and the same for males.\nGiven the conditions, we have:\n\nRisk of heart attack for females who do not visit the doctor: 0.2\nRisk of heart attack for females who visit the doctor: 0.2 - 0.25*0.2 = 0.15\nRisk of heart attack for males who do not visit the doctor:0.4\nRisk of heart attack for males who visit the doctor: 0.4 - 0.25*0.4 = 0.3\n\nNow, let’s represent the treatment group (doctor’s visits) and control group (no doctor’s visits) as A = 1 and A = 0, respectively and simulate our data:\nNow, we calculate the propensity scores, which are the probabilities of treatment given covariates (in this case, sex). This is represented by \\(e(L) = P(A = 1 | L).\\)\nThe sum of the weights times the treatment indicator times the outcome for the treated is:\n[ = ]\nThe sum of the weights times the treatment indicator times the outcome for the untreated is:\n[ = ]\nThe inverse probability of treatment weights (IPTW) are calculated as:\nNow each individuals has a weight associated with their probability of treatment (propsensity score)\nThe sum of the weights times the treatment indicator times the outcome for the treated is:\n[ = ]\nThe sum of the weights times the treatment indicator times the outcome for the untreated is:\n[ = ]\nWe calculate the ATE the difference in these weighted expectations:\n[ATE_{} = - ]\n\n\n[1] -0.08726773\n\n\nThis should provide a more accurate estimate of the ATE given your constraints. It’s important to note that these calculations are based on a hypothetical population and might not exactly reflect the real-world effect\nThe bias in the sample is represented in the causal graph Figure 1\n\n\n\n\n\nFigure 1: Causal graph respents how randomisation works. Although being male affects heart attack, the frequency of males in the treatment condition are balanced.\n\n\n\n\nOur sample is biased.\n\n\n\n\n\nActual_Treatment\nA_1\nA_0\n\n\n\n\nMale\n.25\n.75\n\n\nFemale\n.75\n.25"
  },
  {
    "objectID": "posts/iptw/iptw.html#what-is-iptw",
    "href": "posts/iptw/iptw.html#what-is-iptw",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "What is IPTW?",
    "text": "What is IPTW?\nInverse Probability of Treatment Weighting (IPTW) is a method for estimating causal effects using propensity scores to restore balance in the distribution of confounders within treatment groups. A propensity score as the estimated probabilities of receiving treatment given the observed covariates. By balancing the confounding baseline covariates between the treated and untreated groups, we effectively create a pseudo-population where treatment assignment is independent of the observed covariates.\n\n\n\n\n\nFigure 2: Causal graph respents how randomisation works. Although being male affects heart attack, the frequency of males in the treatment condition are balanced.\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# create data frame\nmy_data &lt;- tibble(\n Weighted_Treatment = c(\n \"Male\",\n \"Female\"),\n A_1 = c(\".5\", \".5\"),\n A_0 = c(\".5\", \".5\"),\n)\n\n# create table \nmy_data %&gt;%\n kbl(format = \"html\") |&gt; \n kable_styling(\"hover\")\n\n\n\n\n\nWeighted_Treatment\nA_1\nA_0\n\n\n\n\nMale\n.5\n.5\n\n\nFemale\n.5\n.5\n\n\n\n\n\n\n\nMathematically, the ATE using IPTW can be represented as follows:\n[ _{IPTW} = - ]\nWhere:\n\n\\(\\hat{ATE}_{IPTW}\\) is the estimated Average Treatment Effect using IPTW.\n\\(Y_{i}\\) is the outcome for individual\\(i\\).\n\\(A_{i}\\) is the treatment status for individual\\(i\\) (1 if treated, 0 if untreated).\n( (L_{i}) ) is the estimated propensity score for individual \\(i\\), which is the predicted probability of treatment given the observed characteristics ( A_{i} ).\n\n(Please note that this is the population ATE. If you want the sample ATE, you can replace the sums in the numerator and denominator with means.)\n\nCreate Weighted Sample: In the weighted sample, each individual is given a weight according to their IPTW to create a pseudopopulation\n\nAfter we have the IPTWs for each individual, we can use these weights to create a weighted sample, or pseudopopulation. This pseudopopulation is used to estimate the Average Treatment Effect (ATE).\nThe weights are used to assign a weight to each individual in the sample. These weights are proportional to the inverse of the probability that the individual received the treatment they did, given their covariates.\nThe weight for each individual can be viewed as the number of times they appear in the pseudopopulation. For example, if an individual has a weight of 1.25, it is as if they appear 1.25 times in the pseudopopulation.\nIn a real analysis, we would use this pseudopopulation to estimate the Average Treatment Effect (ATE). We would fit a model (for example, a logistic regression model if the outcome is binary, or a linear regression model if the outcome is continuous) to this weighted sample, and the estimated effect of the treatment would be our estimate of the ATE.\nHere we will simulate the \\(ATE_{IPTW}\\) by simulation:\n\n# Load necessary libraries\nlibrary(tidyverse)\n\n# Note\n#1. **Treatment assignment:** Treatment assignment must be randomized within each gender group.\n\n#2. **Outcome calculation:** In the calculation of the outcome,the treatment effect should only apply to those who received the treatment.\n\n#3. **IPTW weight calculation:** The weights are  the inverse probability of treatment weights (IPTW), which are used to create a pseudo-population in which treatment assignment is independent of the observed covariates.\n\n#4. **ATE calculation:** The ATE should be calculated as the difference in the mean outcomes between the treated and untreated groups in the IPTW-adjusted population.\n\n\n# Function to generate data and calculate ATE\nsimulate_ATE &lt;- function() {\n  # Define groups\n  N &lt;- 1000\n\n  # Define the risks\n  risk_F &lt;- 0.4\n  risk_M &lt;- 0.6\n  risk_reduction &lt;- 0.25\n  \n  # Create a data frame\n  data &lt;- tibble(\n    gender = rep(c(\"Female\", \"Male\"), each = N/2),\n    treatment = c(rbinom(N/2, 1, 0.6), rbinom(N/2, 1, 0.2))  # Treatment assignment based on propensity scores\n  )\n  \n  # Define outcome based on gender, treatment, and associated risk\n  data &lt;- data %&gt;%\n    mutate(outcome = ifelse(gender == \"Female\",\n                            ifelse(treatment == 1, rbinom(N/2, 1, risk_F - risk_reduction), rbinom(N/2, 1, risk_F)),\n                            ifelse(treatment == 1, rbinom(N/2, 1, risk_M - risk_reduction), rbinom(N/2, 1, risk_M))))\n  \n  # Generate propensity scores using logistic regression\n  model_ps &lt;- glm(treatment ~ gender, data = data, family = \"binomial\")\n  data$ps &lt;- predict(model_ps, type = \"response\")\n  \n  # Calculate IPTW weights\n  data &lt;- data %&gt;% mutate(weight = ifelse(treatment == 1, 1/ps, 1/(1-ps)))\n  \n  # Calculate ATE using IPTW\n  treated_outcome &lt;- with(data, sum(weight[outcome == 1 & treatment == 1]) / sum(weight[treatment == 1]))\n  control_outcome &lt;- with(data, sum(weight[outcome == 1 & treatment == 0]) / sum(weight[treatment == 0]))\n  ATE_iptw &lt;- treated_outcome - control_outcome\n  \n  ATE_iptw\n}\n\n# Set seed for reproducibility\nset.seed(12345)\n\n# Run simulation 500 times\nsimulations &lt;- replicate(500, simulate_ATE())\n\n# Calculate mean and confidence intervals\nmean_ATE &lt;- mean(simulations)\nCI_ATE &lt;- quantile(simulations, c(0.025, 0.975))  # 95% CI\n\n# Print results\nprint(paste(\"95% Confidence Interval for ATE: \", CI_ATE[1], \" - \", CI_ATE[2]))\n\n[1] \"95% Confidence Interval for ATE:  -0.32037215570015  -  -0.18016591005666\"\n\n\nThis code first defines the gender and treatment status of each individual in the sample. Then it calculates the propensity scores, which are the probabilities of receiving receiving the treatment given the individual’s gender. After that, the code calculates the Inverse Probability of Treatment Weights (IPTWs) for each individual. The IPTWs are then used to calculate the Average Treatment Effect (ATE) using the formula provided above. This simulation is repeated 500 times to estimate the confidence interval for the ATE.\nThe result of the simulation is a 95% confidence interval for the Average Treatment Effect (ATE). This provides an estimate of the range within which the true ATE is likely to fall, with 95% confidence.\nTo further clarify the concepts, here is a step-by-step overview of the process:\n\nDefine the population: The population consists of 1,000 individuals, with an equal distribution of males and females.\nAssign treatment: Treatment (doctor’s visits) is assigned based on a Bernoulli distribution, with males being twice as less likely to visit doctors than females.\nCalculate outcomes: The outcome (risk of heart attack) is calculated based on gender and treatment status, with doctor’s visits reducing the risk of heart attacks by 0.25p.\nEstimate propensity scores: Propensity scores, the probability of receiving treatment given the observed covariates, are estimated using a logistic regression model.\nCalculate IPTWs: IPTWs are calculated as the inverse of the propensity scores for the treated, and the inverse of one minus the propensity scores for the untreated.\nCreate weighted sample: The IPTWs are used to create a weighted sample, or pseudopopulation, where each individual’s weight is proportional to the inverse of the probability that they received the treatment they did, given their covariates.\nEstimate ATE: The ATE is estimated as the difference in the mean outcomes between the treated and untreated groups in the pseudopopulation. This is done by fitting a model to the weighted sample and estimating the effect of the treatment.\n\nThe last part of the R code block performs a Monte Carlo simulation to repeat this process 500 times. The result is a distribution of ATE estimates, from which we can derive a 95% confidence interval. The confidence interval provides a range of values within which we expect the true ATE to fall, with 95% confidence.\nIn summary, the IPTW method allows us to estimate causal effects from observational data by addressing the bias due to confounding covariates. In our example, the method helps us estimate the effect of doctor’s visits on heart attack risk, while accounting for gender bias. It’s crucial to note, however, that IPTW only addresses bias due to observed confounders. Any unobserved confounders could still introduce bias into our estimate of the treatment effect.\nFinally, it’s important to check the robustness of the IPTW method under different scenarios. Sensitivity analyses can be performed to assess how changes in the assumptions or model specifications could affect the estimated treatment effect. Additionally, other methods like matching or standard regression adjustment could be used in conjunction with IPTW to ensure the robustness of the findings.\nPlease note that this is a simplified example and in real-world applications, the propensity scores would be estimated using a statistical model such as logistic regression, which could include other covariates. The randomness in the outcome generation and the finite sample size can also result in some variability in the estimated ATE.\nThis R code provides an example of how to calculate the ATE using IPTW. The ATE using IPTW is the difference between these two quantities.\nHowever, in a real-world scenario, these would be the observed outcomes (in this case, the occurrence of heart attack) for the respective groups. These outcomes would then be used to estimate the ATE using IPTW."
  },
  {
    "objectID": "posts/iptw/iptw.html#inverse-probability-of-treatment-weighting-iptw",
    "href": "posts/iptw/iptw.html#inverse-probability-of-treatment-weighting-iptw",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Inverse Probability of Treatment Weighting (IPTW)",
    "text": "Inverse Probability of Treatment Weighting (IPTW)\nInverse Probability of Treatment Weighting (IPTW) is a method employed for estimating causal effects from observational data. This is achieved by using propensity scores to balance covariates between treated and untreated groups, thereby creating a pseudo-population where the treatment assignment is independent of the observed covariates. This approach, akin to G-computation, aids in enhancing the accuracy of causal effect estimation. In this context, we consider IPTW to estimate the Average Treatment Effect (ATE)."
  },
  {
    "objectID": "posts/iptw/iptw.html#bias-in-observational-data-an-example",
    "href": "posts/iptw/iptw.html#bias-in-observational-data-an-example",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Bias in observational data: an example",
    "text": "Bias in observational data: an example\nConsider an observational dataset with measures for gender (L), frequency of doctor’s visits (our treatment A), and heart attack incidence (our outcome Y).\nLet’s assume:\n\nThe 10-year incidence risk of heart attacks is \\(p\\) for females.\nFor males, the risk is \\(2p\\) (twice as high).\nDoctor visits reduce the risk of heart attacks by \\(0.2p\\).\nMales are half as likely to visit doctors as females.\n\nIn our sample of 1,000 individuals:\n\n500 are males (50% of 1,000)\n500 are females (50% of 1,000)\n\nThe overall risk \\(R_{\\text{sample}}\\) in the sample is computed as the weighted sum of the risks in males and females:\n\\(R_{\\text{sample}} = 0.5 \\times 2p + 0.5 \\times p = 1.5p\\)\nGiven that the gender proportions are balanced in our sample, \\(R_{\\text{sample}}\\) should also represent the true risk \\(R_{\\text{population}}\\) in the population:\n\\(R_{\\text{population}} = R_{\\text{sample}} = 1.5p\\)\nHowever, if we also suppose:\n\nDoctor’s visits (the treatment) reduce the risk of a heart attack by \\(0.25p\\).\nMales are twice less likely to visit doctors than females.\n\nUnder these conditions, the causal effect of treatment on the outcome will be biased.\nWe assume the baseline risk for females is \\(0.2\\) and for males is \\(0.4\\) (since they are twice as likely to have heart attacks). The treatment effect for individuals who visit a doctor (both males and females) reduces their risk by \\(0.25p\\).\nHence, we have:\n\nRisk of heart attack for females who do not visit the doctor: \\(0.2\\)\nRisk of heart attack for females who visit the doctor: \\(0.2 - 0.25 \\times 0.2 = 0.15\\)\nRisk of heart attack for males who do not visit the doctor: \\(0.4\\)\nRisk of heart attack for males who visit the doctor: \\(0.4 - 0.25 \\times 0.4 = 0.3\\)\n\nThe bias in the sample is represented in the causal graph Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: Causal graph respents how randomisation works. Although being male affects heart attack, the frequency of males in the treatment condition are balanced.\n\n\n\n\n\nWe represent the treatment group (doctor’s visits) and control group (no doctor’s visits) as A = 1 and A = 0, respectively, and simulate our data:\n\n\n\n\n\n\nActual_Treatment\nA_1\nA_0\n\n\n\n\nMale\n.25\n.75\n\n\nFemale\n.75\n.25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Causal graph respents how randomisation works. Although being male affects heart attack, the frequency of males in the treatment condition are balanced.\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# create data frame\nmy_data &lt;- tibble(\n Weighted_Treatment = c(\n \"Male\",\n \"Female\"),\n A_1 = c(\".5\", \".5\"),\n A_0 = c(\".5\", \".5\"),\n)\n\n# create table \nmy_data %&gt;%\n kbl(format = \"html\") |&gt; \n kable_styling(\"hover\")\n\n\n\n\n\n\nWeighted_Treatment\nA_1\nA_0\n\n\n\n\nMale\n.5\n.5\n\n\nFemale\n.5\n.5"
  },
  {
    "objectID": "posts/iptw/iptw.html#summary",
    "href": "posts/iptw/iptw.html#summary",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Summary",
    "text": "Summary\nIt’s important to note that IPTW doesn’t adjust for unobserved confounders, and the validity of the results depends on the assumption of no unmeasured confounders, the correct specification of the model used to estimate the propensity scores, and the correct specification of the model used to estimate the ATE. In real-world research, we often have to deal with multiple covariates and complex interactions between them, which can further complicate the estimation of propensity scores and IPTWs.\nNevertheless, I hope you get a sense of why IPTW is a powerful tool for causal inference in observational studies. IPTW is powerful because it allows us to obtain balance between confounders within different levels of the treatment."
  },
  {
    "objectID": "posts/iptw/iptw.html#step-1-understanding-iptw",
    "href": "posts/iptw/iptw.html#step-1-understanding-iptw",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Step 1: Understanding IPTW",
    "text": "Step 1: Understanding IPTW\nInverse Probability of Treatment Weighting (IPTW) is a method used to estimate causal effects from observational data. This is achieved by balancing the distribution of confounding variables across treatment and control groups using propensity scores."
  },
  {
    "objectID": "posts/iptw/iptw.html#step-2-propensity-scores",
    "href": "posts/iptw/iptw.html#step-2-propensity-scores",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Step 2: Propensity Scores",
    "text": "Step 2: Propensity Scores\nPropensity scores are the predicted probabilities of receiving treatment given the observed covariates. By balancing these confounding covariates, we essentially construct a pseudo-population where the probability of treatment assignment is independent of the observed covariates. This brings us closer to a randomized experiment scenario, enabling us to estimate the causal effect of treatment."
  },
  {
    "objectID": "posts/iptw/iptw.html#step-3-average-treatment-effect-ate",
    "href": "posts/iptw/iptw.html#step-3-average-treatment-effect-ate",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Step 3: Average Treatment Effect (ATE)",
    "text": "Step 3: Average Treatment Effect (ATE)\nTo apply IPTW, we aim to estimate the Average Treatment Effect (ATE). In its unweighted form, the ATE using IPTW can be represented as:\n[ _{IPTW} = - ]\nHere:\n\n\\(\\hat{ATE}_{IPTW}\\) represents the estimated Average Treatment Effect using IPTW.\n\\(Y_{i}\\) represents the outcome for individual \\(i\\).\n\\(A_{i}\\) is the treatment status for individual \\(i\\) (1 if treated, 0 if untreated).\n\\(\\hat{e}(L_{i})\\) denotes the estimated propensity score for individual \\(i\\), which is the predicted probability of treatment given the observed characteristics \\(L_{i}\\).\n\nThe above formula calculates the difference in outcomes between the treated and untreated individuals, where each individual’s contribution is weighted by the inverse of their probability of receiving the treatment they did, given their covariates. This creates an unweighted or crude estimate of the ATE, as it doesn’t account for potential bias due to confounding covariates."
  },
  {
    "objectID": "posts/iptw/iptw.html#step-4-creating-a-weighted-sample",
    "href": "posts/iptw/iptw.html#step-4-creating-a-weighted-sample",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Step 4: Creating a Weighted Sample",
    "text": "Step 4: Creating a Weighted Sample\nAfter calculating the IPTWs for each individual, we can use these weights to construct a weighted sample, or pseudopopulation. This pseudopopulation is used to estimate the ATE.\nThe weights are used to assign a value to each individual in the sample. These weights are proportional to the inverse of the probability that the individual received the treatment they did, given their covariates.\nIn the context of the pseudopopulation, the weight for each individual can be thought of as the number of times they appear in the pseudopopulation. For instance, if an individual has a weight of 1.25, it is as if they appear 1.25 times in the pseudopopulation."
  },
  {
    "objectID": "posts/iptw/iptw.html#step-5-estimating-the-ate",
    "href": "posts/iptw/iptw.html#step-5-estimating-the-ate",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Step 5: Estimating the ATE",
    "text": "Step 5: Estimating the ATE\nIn practical analysis, we use this pseudopopulation to estimate the ATE. We fit a model (for example, a logistic regression model if the outcome is binary, or a linear regression model if the outcome is continuous) to this weighted sample, and the estimated effect of the Sure, let’s continue from where we left off:"
  },
  {
    "objectID": "posts/iptw/iptw.html#step-5-estimating-the-ate-continued",
    "href": "posts/iptw/iptw.html#step-5-estimating-the-ate-continued",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Step 5: Estimating the ATE (Continued)",
    "text": "Step 5: Estimating the ATE (Continued)\ntreatment serves as our estimate of the ATE. When done correctly, this approach can help us estimate the causal effect of the treatment, while accounting for the confounding variables that could otherwise bias our results."
  },
  {
    "objectID": "posts/iptw/iptw.html#step-6-simulation",
    "href": "posts/iptw/iptw.html#step-6-simulation",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Step 6: Simulation",
    "text": "Step 6: Simulation\nThe next step involves simulating the \\(ATE_{IPTW}\\) to estimate the confidence interval for the ATE. This simulation is usually performed multiple times (say, 500 times) to generate a distribution of ATE estimates, which is used to calculate a confidence interval for the true ATE. This confidence interval provides a range within which we would expect the true ATE to fall with a certain level of confidence, typically 95%."
  },
  {
    "objectID": "posts/iptw/iptw.html#step-7-interpretation",
    "href": "posts/iptw/iptw.html#step-7-interpretation",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Step 7: Interpretation",
    "text": "Step 7: Interpretation\nAfter the simulation, we interpret the results. The IPTW approach allows us to estimate the causal effects from observational data by addressing the bias due to confounding covariates. It’s important to note, however, that the IPTW approach only adjusts for observed confounders; unobserved confounders could still introduce bias into our estimates."
  },
  {
    "objectID": "posts/iptw/iptw.html#step-8-validation",
    "href": "posts/iptw/iptw.html#step-8-validation",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Step 8: Validation",
    "text": "Step 8: Validation\nFinally, it’s crucial to validate the findings. Sensitivity analyses can be conducted to assess how changes in the assumptions or model specifications could affect the estimated treatment effect. Also, other methods like matching or standard regression adjustment could be used alongside IPTW to ensure the robustness of the findings.\nRemember, this is a simplified example. In real-world applications, propensity scores would typically be estimated using more complex statistical models, potentially including a variety of other covariates. Also, the randomness in the outcome generation and finite sample sizes can introduce variability in the estimated ATE."
  },
  {
    "objectID": "posts/iptw/iptw.html#summary-1",
    "href": "posts/iptw/iptw.html#summary-1",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Summary",
    "text": "Summary\nIPTW is a powerful tool for estimating causal effects from observational data, particularly when random assignment to treatment and control groups is not feasible. However, it’s important to be aware of its limitations. The method doesn’t adjust for unobserved confounders, and the validity of the results depends on the assumption of no unmeasured confounders, correct specification of the propensity score model, and correct specification of the model used to estimate the ATE. Despite these challenges, when applied correctly, IPTW can provide valuable insights in fields as diverse as epidemiology, economics, and social sciences.\n\nLooking ahead"
  },
  {
    "objectID": "posts/iptw/iptw.html#iptw-with-time-varying-treatments",
    "href": "posts/iptw/iptw.html#iptw-with-time-varying-treatments",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "IPTW with Time-varying Treatments",
    "text": "IPTW with Time-varying Treatments\nIn longitudinal studies, where treatments can vary over time, we can extend the IPTW method to handle time-varying treatments. For this, we use a concept called the “marginal structural model”. In this model, we estimate the effect of the treatment over time, accounting for the fact that the treatment and covariates can change over time.\nThe weights in this case, often referred to as “stabilized weights”, are calculated slightly differently than in the simple IPTW method. They are designed to reduce the variability of the weights and improve the efficiency of the estimator.\n\nChecking the Balance of Covariates\nAfter calculating the IPTWs and creating the pseudopopulation, it’s important to check the balance of covariates between the treated and untreated groups. This can be done by comparing the distribution of covariates in the treated and untreated groups before and after weighting. If the IPTW method is successful, the distributions of the covariates should be similar in the two groups after weighting.\n\n\nVariance Estimation\nStandard errors and confidence intervals for the ATE estimator using IPTW can be obtained using bootstrapping, a resampling method that provides an empirical estimation of the sampling distribution of a statistic. Alternatively, robust variance estimators can be used.\n\n\nConclusion\nWhile IPTW is a powerful tool for causal inference, it is not without its challenges. It requires correct specification of the treatment model (to estimate propensity scores) and careful interpretation of the results. Further, it only addresses confounding by observed covariates, and unobserved confounding remains a potential source of bias. Despite these challenges, IPTW remains a valuable method in observational studies where randomized controlled trials are not feasible.\nIn practice, IPTW is often used in combination with other methods for causal inference, such as matching or stratification on the propensity score, or doubly robust estimators which combine propensity score methods and outcome regression. Each method has its strengths and limitations, and the choice between methods will depend on the specific research question and the data at hand.\nMoreover, it is crucial to perform diagnostics checks, such as checking for overlap in the propensity scores (common support) and balance of covariates after weighting. Also, sensitivity analyses can be done to assess the robustness of the results to potential unmeasured confounding.\nFinally, the ultimatfe goal is to ensure that the conclusions drawn from observational data about causal effects are as valid and robust as possible. It is in this endeavor that methods like IPTW play a crucial role."
  },
  {
    "objectID": "about.html#purpose",
    "href": "about.html#purpose",
    "title": "About",
    "section": "",
    "text": "The purpose of this site is to convey research to a broader public."
  },
  {
    "objectID": "posts/m-bias/m-bias.html",
    "href": "posts/m-bias/m-bias.html",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "",
    "text": "Elsewhere, we have described our strategy for using three waves of panel data to identify causal effects. For confounding control, we adopt VanderWeele’s modified disjunctive cause criterion:\n\ncontrol for each covariate that is a cause of the exposure, or of the outcome, or of both; exclude from this set any variable known to be an instrumental variable; and include as a covariate any proxy for an unmeasured variable that is a common cause of both the exposure and the outcome (VanderWeele, Mathur, and Chen 2020, 441; VanderWeele 2019).\n\nSuch a criterion might appear to be too liberal. It might seem that we should instead select the minimum adjustment set of confounders necessary for confounding control. Of course, the minimum adjustment set cannot generally be known. However, a liberal inclusion criterion would seem to invite confounding by over-conditioning. We next consider the risks of such liberality in three-wave panel designs."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#summary",
    "href": "posts/m-bias/m-bias.html#summary",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "",
    "text": "Researchers may accidentally induce confounding by over-adjustment.\nM-bias occurs from the over-adjustment of baseline indicators.\nOnly a slight modification in the assumptions of the M-bias graph implies intractable confounding.\nThree waves of panel data that include indicators at baseline both for the exposure and the outcome point to a way out of intractable confounding.\nCausal diagrams help researchers to clarify causal assumptions, however, to address the causal crisis, observational psychologists require longitudinal data."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#assumptions",
    "href": "posts/m-bias/m-bias.html#assumptions",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "Assumptions",
    "text": "Assumptions\n\nYou are interested in psychological science.\nYou have some familiarity with causal diagrams.\nYou want to understand better how to select covariates to control for confounding."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#review",
    "href": "posts/m-bias/m-bias.html#review",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "",
    "text": "Elsewhere, we have described our strategy for using three waves of panel data to identify causal effects. For confounding control, we adopt VanderWeele’s modified disjunctive cause criterion:\n\ncontrol for each covariate that is a cause of the exposure, or of the outcome, or of both; exclude from this set any variable known to be an instrumental variable; and include as a covariate any proxy for an unmeasured variable that is a common cause of both the exposure and the outcome (VanderWeele, Mathur, and Chen 2020, 441; VanderWeele 2019).\n\nSuch a criterion might appear to be too liberal. It might seem that we should instead select the minimum adjustment set of confounders necessary for confounding control. Of course, the minimum adjustment set cannot generally be known. However, a liberal inclusion criterion would seem to invite confounding by over-conditioning. We next consider the risks of such liberality in three-wave panel designs."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#m-bias",
    "href": "posts/m-bias/m-bias.html#m-bias",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "M-bias",
    "text": "M-bias\nM-bias is a form of bias that can arise when we include too many variables in our analysis, a phenomenon known as over-conditioning. Let’s break this down using a concrete example.\nSuppose we’re interested in understanding if being a perfectionist influences a person’s level of humility. We start with the assumption that there’s no direct cause-and-effect relationship between perfectionism (the exposure) and humility (the outcome).\nNow imagine we’re including forgiveness in our analysis. We know that childhood schooling influences both forgiveness and perfectionism, and childhood religion affects forgiveness and humility. If we adjust for forgiveness in our analysis, an indirect path (or backdoor path) is created between perfectionism and humility, leading to M-bias. This path can be illustrated as Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: M-bias: an example of confounding that arises from over-adjustment\n\n\n\n\n\nBy including forgiveness in our model, we’ve inadvertently introduced a correlation between perfectionism and humility where one didn’t previously exist. This is the essence of M-bias."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#seemingly-uncontrollable-confounding",
    "href": "posts/m-bias/m-bias.html#seemingly-uncontrollable-confounding",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "Seemingly uncontrollable confounding",
    "text": "Seemingly uncontrollable confounding\nThe strategy for handling M-bias would seem obvious. Do not condition on forgiveness. However, typically the data do not tell us the true structures of causal relationships. We must rely on assumptions. How would our problem change if, contrary to our previous assumptions, we were to assume that forgiveness causes (i.e. diminishes) perfectionism? Such an assumption would appear theoretically plausible. An intervention that caused me to be more forgiving of others might also cause me to be more forgiving of myself. A causal diagram that incorporates this new assumption is presented in Figure 2. Under our revised assumptions we must adjust on the measured confounder: forgiveness.\n\n\n\n\n\nFigure 2: Confounding control requires adjusting for foregiveness"
  },
  {
    "objectID": "posts/m-bias/m-bias.html#the-modified-disjunctive-cause-criterion-provides-a-way-out",
    "href": "posts/m-bias/m-bias.html#the-modified-disjunctive-cause-criterion-provides-a-way-out",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "The modified disjunctive cause criterion provides a way out",
    "text": "The modified disjunctive cause criterion provides a way out\nThe modified disjunctive cause criterion recommends that we “include as a covariate any proxy for an unmeasured variable that is a common cause of both the exposure and the outcome.”\n\n\n\n\n\nFigure 3: The modified disjunctive cause criterion minimises confounding.\n\n\n\n\nFigure 3 clarifies how application of the modified disjunctive cause criterion may reduce confounding. On this graph, \\(L^1_{t-1}\\) fully mediates the path from childhood schooling to perfectionism. If any variable corresponding to \\(L^1_{t-1}\\) were measured, including it in our model, along with indicators of forgiveness, would block the backdoor path from perfectionism to humility. Furthermore, on this graph, \\(L^2_{t-1}\\) fully mediates the path from childhood religion to humility. If any variable corresponding to \\(L^2_{t-1}\\) were measured, including it in our model would be sufficient to block a backdoor path from perfectionism to humility. Again, the causal structure of reality is unknown. However, by including in the set of measured confounders any \\(l \\in (L^1_{t-1} \\lor L^2_{t-1})\\), we may reduce or even eradicate confounding. We may adopt confounding control using proxies of unmeasured confounders."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#the-spectre-of-confounding-remains",
    "href": "posts/m-bias/m-bias.html#the-spectre-of-confounding-remains",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "The spectre of confounding remains",
    "text": "The spectre of confounding remains\nConsider how conditioning on many baseline confounders may open new opporunities for M-bias. Suppose that charity at baseline is not causally associated with either perfectionism or humility. Suppose further that there are common causes of charity, perfectionism, and humility, such as one’s social network and one’s family relationships as presented in Figure 4. Here, conditioning on charity would induce M-bias. If we are confident that charity does not meet the modified disjunctive cause criterion, then we should exclude charity from our model. However, we repeat our mantra: we cannot be certain any causal diagram reflects the causal structures of reality.\nApplication of the modified disjunctive criterion enables researchers to better use theory for developing strategies of confounding control. However researchers cannot escape theory. With this in mind, we ask: what if theory were to allow charity to affect perfectionism? We consider this question next.\n\n\n\n\n\nFigure 4: Overconditioning remains a threat."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#adjusting-for-both-the-exposure-and-outcome-at-baseline-is-a-powerful-strategy-for-confounding-control.",
    "href": "posts/m-bias/m-bias.html#adjusting-for-both-the-exposure-and-outcome-at-baseline-is-a-powerful-strategy-for-confounding-control.",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "Adjusting for both the exposure and outcome at baseline is a powerful strategy for confounding control.",
    "text": "Adjusting for both the exposure and outcome at baseline is a powerful strategy for confounding control.\nVanderWeele and colleagues disuss reasons for including indicators for both the exposure and outcome at baseline when estimating causal effects (VanderWeele, Mathur, and Chen 2020) (see our application to New Zealand Attitudes and Values Study data here)\nOur discussion of M-bias reveals additional reasons for including these indicators of exposure and outcome at baseline.\n\n\n\n\n\nFigure 5: Conditioning on the baseline exposure and outcome minimises uncontrolled confounding.\n\n\n\n\nWe have assumed that (unmeasured) childhood schooling causes perfectionism, the exposure. Notice that by including measures of the exposure at baseline, the effect of childhood schooling on perfectionism would need to be orthogonal to its effect at baseline.\nFurthermore, we have assumed that (unmeasured) childhood religion causes humility, the outcome. Notice that by including measures of the outcome at baseline, the effect of childhood religion on humility would need to be orthogonal to its effect at baseline.\nAs shown in Figure 5, including measures for both the exposure and outcome at baseline provides a powerful check on unmeasured confounding. For unmeasured confounders to bias effect estimates their effects would need to arise subsequent to their effects on baseline measures.\nFurthermore, the advantage of including baseline indicators both for the exposure and the outcome generalises to the problem of novel M-bias presented in Figure 4. However, as show in Figure 6, adjusting for baseline indicators both for the exposure and the outcome may dramatically reduce or eliminate novel M-bias.\n\n\n\n\n\nFigure 6: Further benefits of conditioning on the baseline exposure and outcome.\n\n\n\n\nAgain we underscore the importance of longitudinal data in deploying effective confounding control: a strategy that includes baseline measures both for the exposure and the outcome requires collecting at least three waves of panel data."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#when-might-adjusting-for-the-baseline-exposure-and-outcome-be-sufficient",
    "href": "posts/m-bias/m-bias.html#when-might-adjusting-for-the-baseline-exposure-and-outcome-be-sufficient",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "When might adjusting for the baseline exposure and outcome be sufficient?",
    "text": "When might adjusting for the baseline exposure and outcome be sufficient?\nFigure 7 presents a model in which we only condition on baseline exposure and outcome. Given the lingering prospects for over-conditioning described in Figure 4, it is worth considering when we would be motivated to adjust for any indicators other than the baseline exposure and the baseline outcome.\n\n\n\n\n\nFigure 7: Conditioning on the baseline exposure and outcome may be sometimes be sufficient for confounding control.\n\n\n\n\nSometimes adjusting only for the baseline exposure and the baseline outcome will be sufficient to control confounding. However, we must again recall that we do not know generally know the causal structure of reality.\nIn Figure 8 we assume that charity at baseline might affect both the exposure, perfectionism, and humility, the outcome. Because the world is dynamic, a confounder might might induce bias even after controlling for pre-exposure perfectionism and pre-exposure humility. If charity were such a cause then including an indicator for charity at baseline would avoid this confounding. Failing to do so would permit confounding. In such an instance, in including the baseline exposure and the baseline outcome would not be sufficient for confounding control, however in the absence of plausible proxies for unmeasured confounders, such inclusion would be necessary for confounding control.\n\n\n\n\n\nFigure 8: Conditioning on the baseline exposure and outcome is not always sufficient for confounding control. We advise using the modified disjunctive cause criterion; we also advise performing sensitivity analysis.\n\n\n\n\nThe world is dynamic. Science learns it’s causal structures only slowly. The modified disjunctive cause criterion minimises reliance on any specific causal diagram. Yet we cannot known whether our confounding control strategy was successful. For this reason, we recommend sensitivity analysis. In our research, we report E-values (VanderWeele and Ding 2017). We reserve discussion of sensitivity analysis for future reports."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#the-causal-crisis-in-psychology-cannot-be-fixed-with-graphs-needed-are-time-series-data.",
    "href": "posts/m-bias/m-bias.html#the-causal-crisis-in-psychology-cannot-be-fixed-with-graphs-needed-are-time-series-data.",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "The causal crisis in psychology cannot be fixed with graphs: needed are time series data.",
    "text": "The causal crisis in psychology cannot be fixed with graphs: needed are time series data.\nTo “control” for confounding, psychologists often include many variables in their regression models. There is growing awareness that including many variables in one’s regression model may instead induce bias. Over-adjustment bias arises when we adjust for a mediator along the path from the exposure to an outcome. It also arises when we adjust for a common effect of exposure and an outcome, or post-treatment collider bias (J. Bulbulia et al. 2021). It is mediator bias and post-treatment collider bias that forms the focus of most recent treatments of confounding control. We discuss mediator bias and post-treatment collider bias in the context of treatment-confounder feedback.\nIt is with mediator bias and post-treatment collider bias in mind that many researchers advise parsimony when selecting variables for confounding control (McElreath 2020). Furthermore, freely available software assists researchers in the search for minimally sufficient adjustment sets (Barrett 2021). However, as we have been emphasising all along, scientists cannot generally know whether any assumed causal diagram reflects the true causal structure of reality. Our self-confidence in a given causal diagram is too flimsy a peg on which which to hang all our science.\nThere is hope. With at least three waves of repeated measures data we may avoid the threat of over-adjustment bias from mediator and post-treatment collider confounding. The structure of times series data may require special methods (such as handling treatment-confounder feedback.) However, when variables are repeatedly measured over time we can see, and avert, many concerns about post-treatment biases.1 Three-wave longitudinal designs allow us to measure an outcome after an exposure, measure confounders before that exposure, and include in the set of confounders measured at baseline indicators both for the exposure and for the outcome. As such, the time series allows us to preserve the temporal order needed to infer causal effects. By preserving this order we dramatically reduce the threats of mediator bias and post-treatment collider bias. Although assumptions cannot be avoided, three waves of panel data allow us to relax the very strong assumptions about timing in the occurrence of outcome, exposure, and confounders that are needed in single wave studies and many pre-post studies.\nHere, we have considered the specific threats to causal inference from pre-treatment confounding. We have considered how a modified disjunctive cause criterion addresses the threat of M-bias, and why the inclusion at baseline of indicators both for the exposure and the outcome is an especially powerful strategy for confounding control.\nPsychological science faces a casual crisis whose magnitude has yet to be fully appreciated (J. A. Bulbulia 2022). It is encouraging that many psychological scientists are better understanding the importance of causal diagrams (Rohrer 2018). However, there is considerable work to be done still in conveying the importance of longitudinal data collection. Causal diagrams will continue to help psychological scientists to appreciate the discipline’s causal crisis, however, the causal crisis will not be resolved with causal diagrams alone. Transforming observational psychology into a science turns on the quality and diversity of the discipline’s longitudinal data collection."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#acknowledgements",
    "href": "posts/m-bias/m-bias.html#acknowledgements",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nI am grateful to Templeton Religion Trust Grant 0418 for supporting my work.1"
  },
  {
    "objectID": "posts/m-bias/m-bias.html#footnotes",
    "href": "posts/m-bias/m-bias.html#footnotes",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe funders played no role in the design or interpretation of this research.↩︎"
  },
  {
    "objectID": "posts/m-bias/m-bias.html#the-modified-disjunctive-cause-criterion",
    "href": "posts/m-bias/m-bias.html#the-modified-disjunctive-cause-criterion",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "The modified disjunctive cause criterion",
    "text": "The modified disjunctive cause criterion\nThe modified disjunctive cause criterion recommends that we “include as a covariate any proxy for an unmeasured variable that is a common cause of both the exposure and the outcome.”\n\n\n\n\n\nFigure 3: The modified disjunctive cause criterion minimises confounding.\n\n\n\n\nFigure 3 clarifies how application of the modified disjunctive cause criterion may reduce confounding. On this graph, \\(L^1_{t-1}\\) fully mediates the path from childhood schooling to perfectionism. If any variable corresponding to \\(L^1_{t-1}\\) were measured, including it in our model, along with indicators of forgiveness, would block the backdoor path from perfectionism to humility. Furthermore, on this graph, \\(L^2_{t-1}\\) fully mediates the path from childhood religion to humility. If any variable corresponding to \\(L^2_{t-1}\\) were measured, including it in our model would be sufficient to block a backdoor path from perfectionism to humility. Again, the causal structure of reality is unknown. However, by including in the set of measured confounders any \\(l \\in (L^1_{t-1} \\lor L^2_{t-1})\\), we may reduce or even eradicate confounding. We may adopt confounding control using proxies of unmeasured confounders."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#the-spectre-of-confounding",
    "href": "posts/m-bias/m-bias.html#the-spectre-of-confounding",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "The spectre of confounding",
    "text": "The spectre of confounding\nConsider how conditioning on many baseline confounders may open new opporunities for M-bias. Suppose that charity at baseline is not causally associated with either perfectionism or humility. Suppose further that there are common causes of charity, perfectionism, and humility, such as one’s social network and one’s family relationships as presented in Figure 4. Here, conditioning on charity would induce M-bias. If we are confident that charity does not meet the modified disjunctive cause criterion, then we should exclude charity from our model. However, we repeat our mantra: we cannot be certain any causal diagram reflects the causal structures of reality.\nApplication of the modified disjunctive criterion enables researchers to better use theory for developing strategies of confounding control. However researchers cannot escape theory. With this in mind, we ask: what if theory were to allow charity to affect perfectionism? We consider this question next.\n\n\n\n\n\nFigure 4: Overconditioning remains a threat."
  },
  {
    "objectID": "posts/m-bias/m-bias.html#the-power-of-baseline-measures",
    "href": "posts/m-bias/m-bias.html#the-power-of-baseline-measures",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "The Power of Baseline Measures",
    "text": "The Power of Baseline Measures\nOne might think the solution is simple - don’t include forgiveness in the model. However, our understanding of causal relationships is often imperfect, and there may be plausible reasons to believe that forgiveness does, in fact, influence perfectionism. If this were the case, to avoid bias, we would need to condition on a proxy of the unmeasured variables. This strategy might not completely avoid bias, which is why it is important to include sensitivity analyses to assess how much unmeasured confounding would be required to explain a result away (VanderWeele and Ding 2017)"
  },
  {
    "objectID": "posts/m-bias/m-bias.html#conclusion",
    "href": "posts/m-bias/m-bias.html#conclusion",
    "title": "M-Bias: Confounding Control Using Three Waves of Panel Data",
    "section": "Conclusion",
    "text": "Conclusion\nIn our pursuit of understanding causal relationships, we must carefully navigate the risk of M-bias—a form of confounding that can emerge from over-adjusting for variables. We’ve outlined a strategy to mitigate this bias by including both prior measurements of the exposure and the outcome in our studies. This approach provides a robust mechanism to control for unmeasured confounders that might otherwise skew our results. However, even with these measures, we cannot guarantee the elimination of all confounding. For this reason, we also conduct sensitivity analysis using E-values to assess the robustness of our findings to potential unmeasured confounding. E-values provide a quantitative measure of the minimum strength an unmeasured confounder would need to fully explain away an observed association.\nIn future posts, we will delve more deeply into the concept of E-values and their role in robust causal inference. By leveraging strategies for confounding control that include previous measures of the outcome and exposure variables, as well as senstivity analysis, we strive for more reliable, accurate insights in our studies."
  },
  {
    "objectID": "posts/iptw/iptw.html#looking-ahead",
    "href": "posts/iptw/iptw.html#looking-ahead",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nIPTW with Time-varying Treatments\nIn longitudinal studies, where treatments can vary over time, we can extend the IPTW method to handle time-varying treatments. For this, we use a concept called the “marginal structural model”. In this model, we estimate the effect of the treatment over time, accounting for the fact that the treatment and covariates can change over time. In future posts, we will explore causal inference with time-varying treatments."
  },
  {
    "objectID": "posts/iptw/iptw.html#simulation",
    "href": "posts/iptw/iptw.html#simulation",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Simulation",
    "text": "Simulation\n\n# Load necessary libraries\nlibrary(tidyverse)\n\n# Note\n#1. **Treatment assignment:** Treatment assignment must be randomized within each gender group.\n\n#2. **Outcome calculation:** In the calculation of the outcome,the treatment effect should only apply to those who received the treatment.\n\n#3. **IPTW weight calculation:** The weights are  the inverse probability of treatment weights (IPTW), which are used to create a pseudo-population in which treatment assignment is independent of the observed covariates.\n\n#4. **ATE calculation:** The ATE should be calculated as the difference in the mean outcomes between the treated and untreated groups in the IPTW-adjusted population.\n\n\n# Function to generate data and calculate ATE\nsimulate_ATE &lt;- function() {\n  # Define groups\n  N &lt;- 1000\n\n  # Define the risks\n  risk_F &lt;- 0.4\n  risk_M &lt;- 0.6\n  risk_reduction &lt;- 0.25\n  \n  # Create a data frame\n  data &lt;- tibble(\n    gender = rep(c(\"Female\", \"Male\"), each = N/2),\n    treatment = c(rbinom(N/2, 1, 0.6), rbinom(N/2, 1, 0.2))  # Treatment assignment based on propensity scores\n  )\n  \n  # Define outcome based on gender, treatment, and associated risk\n  data &lt;- data %&gt;%\n    mutate(outcome = ifelse(gender == \"Female\",\n                            ifelse(treatment == 1, rbinom(N/2, 1, risk_F - risk_reduction), rbinom(N/2, 1, risk_F)),\n                            ifelse(treatment == 1, rbinom(N/2, 1, risk_M - risk_reduction), rbinom(N/2, 1, risk_M))))\n  \n  # Generate propensity scores using logistic regression\n  model_ps &lt;- glm(treatment ~ gender, data = data, family = \"binomial\")\n  data$ps &lt;- predict(model_ps, type = \"response\")\n  \n  # Calculate IPTW weights\n  data &lt;- data %&gt;% mutate(weight = ifelse(treatment == 1, 1/ps, 1/(1-ps)))\n  \n  # Calculate ATE using IPTW\n  treated_outcome &lt;- with(data, sum(weight[outcome == 1 & treatment == 1]) / sum(weight[treatment == 1]))\n  control_outcome &lt;- with(data, sum(weight[outcome == 1 & treatment == 0]) / sum(weight[treatment == 0]))\n  ATE_iptw &lt;- treated_outcome - control_outcome\n  \n  ATE_iptw\n}\n\n# Set seed for reproducibility\nset.seed(12345)\n\n# Run simulation 500 times\nsimulations &lt;- replicate(1000, simulate_ATE())\n\n# Calculate mean and confidence intervals\nmean_ATE &lt;- mean(simulations)\nCI_ATE &lt;- round(quantile(simulations, c(0.025, 0.975)),3)  # 95% CI\n\n\n# Print results\nprint(paste(\"95% Confidence Interval for ATE: \", CI_ATE[1], \" - \", CI_ATE[2]))\n\n[1] \"95% Confidence Interval for ATE:  -0.32  -  -0.182\"\n\n\nIn this simulation we:\n\ndefine the population: the population consists of 1,000 individuals, with an equal distribution of males and females.\nassign treatment: treatment (doctor’s visits) is assigned based on a Bernoulli distribution, with males being twice as less likely to visit doctors than females.\ncalculate outcomes: The outcome (risk of heart attack) is calculated based on gender and treatment status, with doctor’s visits reducing the risk of heart attacks by 0.25p.\nestimate propensity scores: propensity scores, the probability of receiving treatment given the observed covariates, are estimated using a logistic regression model.\ncalculate IPTWs: IPTWs are calculated as the inverse of the propensity scores for the treated, and the inverse of one minus the propensity scores for the untreated.\ncreate weighted sample: The IPTWs are used to create a weighted sample, or pseudopopulation, where each individual’s weight is proportional to the inverse of the probability that they received the treatment they did, given their covariates.\nestimate the ATE and obtain confidence intervals. The estimated ATE is expected difference in the mean outcomes between the treated and untreated groups in the pseudopopulation. This is done by fitting a model to the weighted sample and estimating the effect of the treatment. Confidence intervals may be obtained by bootstrapping, the delta-method, or simulation based inference (see: (Greifer et al. 2023)).\n\nThe last part of the R code block performs a Monte Carlo simulation to repeat this process 1000 times. The result is a distribution of ATE estimates, from which we can derive a 95% confidence interval. The confidence interval provides a range of values within which we expect the true ATE to fall, with 95% confidence."
  },
  {
    "objectID": "posts/iptw/iptw.html#addressing-bias-using-iptw",
    "href": "posts/iptw/iptw.html#addressing-bias-using-iptw",
    "title": "Inverse Probability of Treatment Weighting: A Practical Guide",
    "section": "Addressing bias using IPTW",
    "text": "Addressing bias using IPTW\nMathematically, the ATE using IPTW can be represented as follows: ### Inverse Probability of Treatment Weighting (IPTW) Estimator\nStep 1 Estimate the propensity score. The propensity score \\(\\hat{e}\\) is the conditional probability of the exposure \\(A = 1\\), given the covariates \\(L\\). This can be modelled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.\n\\[e = P(A = 1 | L) = f_A(L; \\theta_A)\\]\nHere, \\(f_A(L; \\theta_A)\\) is a function that estimates the probability of the exposure \\(A = 1\\) given covariates \\(L\\). (In classical IPTW, the model is a logistic or multinomial model for the treatment, predicted by covariates that are also associated with the outcome.) Then, we calculate the weights for each individual, denoted as \\(v\\), using the estimated propensity score:\n\\[\nv =\n\\begin{cases}\n\\frac{1}{e} & \\text{if } A = 1 \\\\\n\\frac{1}{1-e} & \\text{if } A = 0\n\\end{cases}\n\\]\nThus, \\(v\\) depends on \\(A\\), and is calculated as the inverse of the propensity score for exposed individuals and as the inverse of \\(1-e\\) for unexposed individuals.\nStep 2 Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome \\(Y\\), conditional on the exposure \\(A\\). This can be represented as:\n\\[ \\hat{E}(Y|A; V) = f_Y(A ; \\theta_Y, V) \\]\nIn this model, \\(f_Y\\) is a function (here, a weighted regression model) with parameters \\(θ_Y\\). The weights \\(V\\) are incorporated into the estimation process, affecting how much each observation contributes to the estimation of \\(θ_Y\\), but they are not themselves an additional variable within the model.\nStep 3 Simulate potential outcomes. For each individual, simulate their potential outcome under the hypothetical scenario where everyone is exposed to the intervention \\(A=a\\) regardless of their actual exposure level:\n\\[\\hat{E}(a) = \\hat{E}[Y_i|A=a; \\hat{\\theta}_Y, v_i]\\]\nand also under the hypothetical scenario where everyone is exposed to intervention \\(A=a'\\):\n\\[\\hat{E}(a') = \\hat{E}[Y_i|A=a'; \\hat{\\theta}_Y, v_i]\\]\nThus the expectation is calculated for each individual \\(i\\), with individual-specific weights \\(v_i\\).\nStep 4 Estimate the average causal effect as the difference in the predicted outcomes:\n\\[\\hat{\\delta} = \\hat{E}[Y(a)] - \\hat{E}[Y(a')]\\]\nThe estimated difference \\(\\hat{\\delta}\\) represents the average causal effect. (In NZAVS research we use simulation-based inference methods to compute standard errors and confidence intervals using the clarify` package in R (Greifer et al. 2023) (Note, in the following illustration, for simplicity, we use monte-carlo simulation)"
  },
  {
    "objectID": "posts/confounder-treatment-feedback/conf-out-feedback.html",
    "href": "posts/confounder-treatment-feedback/conf-out-feedback.html",
    "title": "On the Problem of Treatment Confounder Feedback",
    "section": "",
    "text": "Causation occurs in time. Therefore, investigating the relationship between cause and effect requires time series data.\nCausality is also dynamic. Where there is Treatment-Confounder Feedback, the relationship between cause and effect cannot be identified using standard regression methods, including multi-level regression and structural equation models. Instead, special methods - “G-methods” - are needed.\nHere, I use three causal graphs to describe a problem of treatment-confounder feedback, and direct readers to G-methods for its solution."
  },
  {
    "objectID": "posts/confounder-treatment-feedback/conf-out-feedback.html#purpose",
    "href": "posts/confounder-treatment-feedback/conf-out-feedback.html#purpose",
    "title": "On the Problem of Treatment Confounder Feedback",
    "section": "",
    "text": "Causation occurs in time. Therefore, investigating the relationship between cause and effect requires time series data.\nCausality is also dynamic. Where there is Treatment-Confounder Feedback, the relationship between cause and effect cannot be identified using standard regression methods, including multi-level regression and structural equation models. Instead, special methods - “G-methods” - are needed.\nHere, I use three causal graphs to describe a problem of treatment-confounder feedback, and direct readers to G-methods for its solution."
  },
  {
    "objectID": "posts/confounder-treatment-feedback/conf-out-feedback.html#my-assumptions-about-you",
    "href": "posts/confounder-treatment-feedback/conf-out-feedback.html#my-assumptions-about-you",
    "title": "On the Problem of Treatment Confounder Feedback",
    "section": "My assumptions about you",
    "text": "My assumptions about you\n\nYou are interested in psychological science.\nYou understand how to read causal graphs 1\nYour “go-to” method for time-series analysis is either a latent growth curve or a multi-level model."
  },
  {
    "objectID": "posts/confounder-treatment-feedback/conf-out-feedback.html#confounding-by-common-cause",
    "href": "posts/confounder-treatment-feedback/conf-out-feedback.html#confounding-by-common-cause",
    "title": "On the Problem of Treatment Confounder Feedback",
    "section": "Confounding by Common Cause",
    "text": "Confounding by Common Cause\nSuppose we wish to compute the causal effect of treatment \\(A\\) on outcome \\(Y\\). Because \\(L\\) is a common cause of both \\(A\\) and \\(Y\\), \\(L\\) will lead to an association between \\(A\\) and \\(Y\\). We face confounding by common cause. The good news: where \\(L\\) is measured, a regression model that conditions on \\(L\\) will break the association between \\(A\\) and \\(Y\\). Again, causation occurs in time. We index measured nodes to ensure our data adhere to time’s arrow\n\n\nShow the code\n\\usetikzlibrary{positioning}\n\\usetikzlibrary{shapes.geometric}\n\\usetikzlibrary{arrows}\n\\usetikzlibrary{decorations}\n\\tikzstyle{Arrow} = [-&gt;, thin, preaction = {decorate}]\n\\tikzset{&gt;=latex}\n\n\\begin{tikzpicture}[squarednode/.style={rectangle, draw=gray!90, fill=gray!5, auto}]\n\\tikzset{&gt;=latex}\n\\tikzstyle{Arrow} = [-&gt;, thin, preaction = {decorate}]\n\\tikzstyle{DoubleArrow} = [-, preaction = {decorate}]\n\\node[squarednode] (1) {$L_{t-1}$};\n\\node[right =of 1] (2) {$A_{t}$};\n\\node[right =of 2] (3) {$Y_{t+1}$};\n\\draw[Arrow,bend left] (1) to (3);\n\\draw[Arrow] (1) to (2);\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/confounder-treatment-feedback/conf-out-feedback.html#confounding-by-over-conditioning",
    "href": "posts/confounder-treatment-feedback/conf-out-feedback.html#confounding-by-over-conditioning",
    "title": "On the Problem of Treatment Confounder Feedback",
    "section": "Confounding by Over-Conditioning",
    "text": "Confounding by Over-Conditioning\nSuppose \\(L_{t+1}\\) is an effect of \\(A_{t}\\). To condition on the common effect will induce a spurious association between \\(A_t\\) and \\(Y_{t+1}\\) through the unmeasured confounder \\(U\\) (red path). We may avoid this problem by excluding \\(L_{t+1}\\) from our regression model. To know whether exclusion is warranted requires indexing the relative occurrences of \\(A\\) and \\(L\\). However, without time-series data, we cannot generally know whether \\(L\\) is a cause of \\(A\\) or its effect. Figures 1 and 2 illustrate the importance of collecting time-series data to infer causality. Although psychological scientists are familiar with adjustment by regression to address confounding by common cause, we are less familiar with the hazards of over-conditioning. Generally, confounding control in any observational science requires time series data.\n\n\nShow the code\n\\usetikzlibrary{positioning}\n\\usetikzlibrary{shapes.geometric}\n\\usetikzlibrary{arrows}\n\\usetikzlibrary{decorations}\n\\tikzstyle{Arrow} = [-&gt;, thin, preaction = {decorate}]\n\\tikzset{&gt;=latex}\n\n\\begin{tikzpicture}\n%\\node [draw=none, align=center, font=\\small] at (2,1) {\\bf Condition on child of collider};\n\\node [draw = none, inner sep = 1] (U) at (0, 0) {$U$};\n\\node [draw = none, inner sep = 1] (A) at (.75, 0) {$A_{0}$};\n\\node [rectangle, draw=red, thick](L) at (1.75, 0) {$L_{1}$};\n\\node [draw = none, inner sep = 1] (Y) at (3, 0) {$Y_{2}$};\n\\draw [-latex, bend right=30, draw = red] (U) to (L);\n\\draw [-latex, bend left = 30, draw=red] (U) to (Y);\n\\draw [-latex,draw=red] (A) to (L);\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/confounder-treatment-feedback/conf-out-feedback.html#confounding-control-for-treatment-confounder-feedback-damned-if-you-condition-damned-if-you-do-not.",
    "href": "posts/confounder-treatment-feedback/conf-out-feedback.html#confounding-control-for-treatment-confounder-feedback-damned-if-you-condition-damned-if-you-do-not.",
    "title": "On the Problem of Treatment Confounder Feedback",
    "section": "Confounding control for Treatment-Confounder Feedback: Damned if you condition damned if you do not.",
    "text": "Confounding control for Treatment-Confounder Feedback: Damned if you condition damned if you do not.\nSuppose we collect time series data. Suppose further that conditioning on \\(L\\) blocks an unmeasured common cause \\(U\\) of future treatments \\(A\\) and future outcomes \\(Y\\). Suppose further, as in Figure 2, past states of \\(A\\) affect future states of \\(L\\). Notice, regression faces a damned-if-we-do-damned-if-we-don’t adjustment challenge. On the one hand, to avoid confounding by a common cause we must adjust for \\(L\\) at all time points. On the other hand, adjusting for \\(L_{t+1}\\) induces confounding by over-conditioning (paths in red). **Regression, including multi-level regression and structural equation models, must be abandoned.* There are alternatives to regression called G-methods that may address treatment-confounder feedback. One of these methods, the Marginal Structural Model, replaces \\(L\\) with inverse probability weights for the exposure. G-methods are described in Chapters 12 and 13 of Hernan and Robin’s(Hernan and Robins 2023)2\n\nHernan, M. A., and J. M. Robins. 2023. Causal Inference. Chapman & Hall/CRC Monographs on Statistics & Applied Probab. Taylor & Francis. https://books.google.co.nz/books?id=\\_KnHIAAACAAJ.\n\n\nShow the code\n\\usetikzlibrary{positioning}\n\\usetikzlibrary{shapes.geometric}\n\\usetikzlibrary{arrows}\n\\usetikzlibrary{decorations}\n\\tikzstyle{Arrow} = [-&gt;, thin, preaction = {decorate}]\n\\tikzset{&gt;=latex}\n\n\\begin{tikzpicture}[squarednode/.style={rectangle, draw=red!60, fill=red!5}, scale = 4]\n\\tikzset{&gt;=latex}\n\\tikzstyle{Arrow} = [-&gt;, thin, preaction = {decorate}]\n\\tikzstyle{DoubleArrow} = [-, thick, dotted, preaction = {decorate}]\n\n\\node[draw=black, thick] (1) {L$_{t-1}$};\n\\node[right =of 1] (2) {A$_{t}$};\n\\node[right =of 2] (3) {Y$_{t+1}$};\n\\node[squarednode, right =of 3] (4) {L$_{t+1}$};\n\\node[right =of 4] (5) {A$_{t+1}$};\n\\node[right =of 5] (6) {Y$_{t+2}$};\n\\node[left =of 1] (7) {U};\n\\draw[Arrow] (1) -- (2);\n\\draw[Arrow] (4) -- (5);\n\\draw[Arrow] (7) to (1);\n\\draw[DoubleArrow, red, bend left=40] (2) to (6);\n\\draw[Arrow, bend right, red] (7) to (6);\n\\draw[Arrow, bend right, red] (7) to (4);\n\\draw[Arrow, bend right] (7) to (3);\n\\draw[Arrow, bend left, red] (2) to (4);\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/confounder-treatment-feedback/conf-out-feedback.html#importance",
    "href": "posts/confounder-treatment-feedback/conf-out-feedback.html#importance",
    "title": "On the Problem of Treatment Confounder Feedback",
    "section": "Importance",
    "text": "Importance\nI write this report to encourage psychological scientists to (1) collect time-series data and (2) address treatment-confounder feedback by employing G-methods. I do not write this report to cast stones. My published work offers ample illustrations of the problems that I describe here. On a positive note, a causal revolution in psychological science is upon us. Our best science remains ahead of us (VanderWeele 2015).\n\nVanderWeele, Tyler. 2015. Explanation in Causal Inference: Methods for Mediation and Interaction. Oxford University Press."
  },
  {
    "objectID": "posts/confounder-treatment-feedback/conf-out-feedback.html#references",
    "href": "posts/confounder-treatment-feedback/conf-out-feedback.html#references",
    "title": "On the Problem of Treatment Confounder Feedback",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "posts/confounder-treatment-feedback/conf-out-feedback.html#footnotes",
    "href": "posts/confounder-treatment-feedback/conf-out-feedback.html#footnotes",
    "title": "On the Problem of Treatment Confounder Feedback",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI will soon write a tutorial here for those who are unfamiliar↩︎\nWe draw the minimum number of paths to clarify the problem.↩︎"
  },
  {
    "objectID": "posts/trust-science/trust-science.html#nzavs-report-on-institutional-trust-prepost-covid",
    "href": "posts/trust-science/trust-science.html#nzavs-report-on-institutional-trust-prepost-covid",
    "title": "Institutional Trust in New Zealand Pre/Post COVID-19 Pandemic",
    "section": "",
    "text": "We investigate changes to institutional trust among New Zealanders from the pre-pandemic period in 2019 to 2022.\nThe New Zealand Attitudes and Values Study uses a two-item scale to measure Trust in Science\n\n“I have a high degree of confidence in the scientific community.”(Nisbet, Cooper, and Garrett 2015)\n“Our society places too much emphasis on science.”(reverse coded)\n\nWe average these scores to form a single score (Hartman et al. 2017). These items were introduced in NZAVS Wave 11 (2019 - 2020).\nPrevious research using a propensity score design reported on changes in Trust in Science during the first three weeks of New Zealand’s COVID lockdown in March and April 2020 (Sibley et al. 2020).\nCOVID-19 Government response (Marques et al. 2022)\n\n“I trust the Government to make sensible decisions about how to best manage COVID-19 in New Zealand.”\n“The New Zealand government response to COVID-19.”\n\nTrust in politicians (Sibley et al. 2020)\n\n“Politicians in New Zealand can generally be trusted.”\n\nInstitutional trust in police (Tyler 2005)\n\n“People’s basic rights are well protected by the New Zealand Police.”\n“There are many things about the New Zealand Police and its policies that need to be changed.”\n“The New Zealand Police care about the well-being of everyone they deal with.”\n\nGeneral tendency to believe in conspiracies(Lantian et al. 2016)\n\n“I think that the official version of major world events given by authorities often hides the truth.”\n\n\n\n\n\nShow the code\n# read data\ndat &lt;- arrow::read_parquet(pull_path)\n\n# sometimes arrow objects give me trouble\ndat &lt;- as.data.frame(dat)\n\n\n# create covid timeline variables, select waves of interest. \ndt &lt;- dat |&gt;\n  data.frame() |&gt;\n# create covid timeline \n mutate(covid_condition = as.factor(ifelse(\n    TSCORE &lt; 3922,\n    \"pre_covid\",\n    ifelse(TSCORE &gt;= 3922 &\n             TSCORE &lt;= 3954, \"lockdown\",\n           \"post_lockdown\")\n  ))) |&gt; \n  mutate(covid_condition = factor(covid_condition, levels = c(\"pre_covid\", \"lockdown\", \"post_lockdown\"))) |&gt; # order levels\n  # select waves\n  dplyr::filter(Wave == 2019| Wave == 2020| Wave == 2021) |&gt;\n    dplyr::filter(\n      (Wave == 2019  &\n         YearMeasured  == 1 & !is.na(covid_condition)) |\n      (Wave == 2020) |\n      (Wave == 2021)) |&gt;  \n  group_by(Id) |&gt; \n  # inclusion criteria, all those who participated in 2019\n  dplyr::mutate(org2019 = ifelse(Wave == 2019 &\n                                   YearMeasured == 1, 1, 0)) |&gt;  # creating an indicator for the first wave\n  dplyr::mutate(hold19 = mean(org2019, na.rm = TRUE)) |&gt;  # Hack\n  dplyr::filter(hold19 &gt; 0) |&gt; # hack to enable repeat of baselin\n  fill(w_GendAgeEuro, .direction = \"down\") |&gt; # weights are all for 2018. Fill if missing\n  ungroup() |&gt;\n  droplevels() |&gt;\n  mutate(time = as.numeric(Wave) - 1) |&gt;\n  arrange(Id, time) |&gt;\n  select(\n    Id,\n    covid_condition,\n    YearMeasured,\n    COVID19.Timeline,\n    w_GendAgeEuro, # survey weights for PATT\n    time,\n    TSCORE,\n    Wave,\n    Partner,\n    Euro,\n    EthCat,\n    GenCohort,\n    # Gender3,\n    Male,\n    SampleFrame,\n    NZSEI13,\n    NZDep2018,\n    Rural_GCH2018,\n    REGC_2022,\n    CONSCIENTIOUSNESS,\n    OPENNESS,\n    HONESTY_HUMILITY,\n    EXTRAVERSION,\n    NEUROTICISM,\n    AGREEABLENESS,\n    edu_n,\n    Employed,\n    BornNZ,\n    Pol.Orient,\n    Pol.Wing,\n    Parent,\n    Relid,\n    SDO,\n    RWA,\n    ConspiracyBeliefs,\n    SCIENCE.TRUST,\n    POLICE.TRUST,\n    COVID.TrustGovtResponse,\n    Pol.PoliticianTrust#,\n  # ScienceTrust01, # individual item\n  # ScienceTrust02r  # individual item\n  ) |&gt; \n  rename(\n  Conspiracy_Beliefs  = ConspiracyBeliefs,\n  Trust_in_Science =  SCIENCE.TRUST,\n  Trust_in_Politicians = Pol.PoliticianTrust,\n  Trust_in_Police = POLICE.TRUST,\n  Trust_in_Govt_Covid_Response = COVID.TrustGovtResponse, \n  ) |&gt; \n  droplevels() |&gt; \n  arrange(Id,Wave)\n\n\n\n\nShow the code\n# this code creates a table\n# function to make tables simple         \n# simplify\nmy.render.cont &lt;- function(x) {\n  with(stats.apply.rounding(stats.default(x), digits=3), c(\"\",\n                                                           \"Mean (SD)\"=sprintf(\"%s (&plusmn; %s)\", MEAN, SD)))\n}\n\nmy.render.cat &lt;- function(x) {\n  c(\"\", sapply(stats.default(x), function(y) with(y,\n                                                  sprintf(\"%d (%0.0f %%)\", FREQ, PCT))))\n}\n\n\n# select only 2019-2021\ndt_19 &lt;-dt |&gt; \n  dplyr::filter(Wave == 2019)\n\n\ntab_19_trust &lt;- table1::table1(\n  ~ Trust_in_Science +\n    Trust_in_Politicians +\n    Trust_in_Police +\n    Conspiracy_Beliefs| covid_condition,\n  data = dt_19,\n  overall = FALSE,\n  render.continuous = my.render.cont,\n  render.categorical = my.render.cat\n)\n\n# needed for markdown tables\ntab_19_trust &lt;- data.frame( tab_19_trust )\n\ntab_19_trust &lt;- tab_19_trust |&gt; \n    rename(\"Forms of Institutional Trust\" = X.)\n\n# show\ntab_19_trust |&gt;\n  kbl(format = \"markdown\", booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nForms of Institutional Trust\npre_covid\nlockdown\npost_lockdown\n\n\n\n\n\n(N=29812)\n(N=3511)\n(N=9358)\n\n\nTrust_in_Science\n\n\n\n\n\nMean (SD)\n5.36 (± 1.28)\n5.66 (± 1.23)\n5.55 (± 1.27)\n\n\nMissing\n289 (1.0%)\n16 (0.5%)\n70 (0.7%)\n\n\nTrust_in_Politicians\n\n\n\n\n\nMean (SD)\n3.72 (± 1.44)\n4.00 (± 1.48)\n3.78 (± 1.48)\n\n\nMissing\n685 (2.3%)\n25 (0.7%)\n143 (1.5%)\n\n\nTrust_in_Police\n\n\n\n\n\nMean (SD)\n4.61 (± 1.23)\n4.60 (± 1.34)\n4.50 (± 1.33)\n\n\nMissing\n12 (0.0%)\n0 (0%)\n3 (0.0%)\n\n\nConspiracy_Beliefs\n\n\n\n\n\nMean (SD)\n4.38 (± 1.60)\n4.29 (± 1.68)\n4.31 (± 1.69)\n\n\nMissing\n940 (3.2%)\n43 (1.2%)\n214 (2.3%)\n\n\n\n\n\nHere is a graph of the same.\n\n\nShow the code\ndt_temp_19 &lt;- dt_19 |&gt; select(\n  covid_condition,\n  Trust_in_Science,\n  Trust_in_Politicians,\n  Trust_in_Police,\n  Conspiracy_Beliefs\n)\n\n\n# boxplot dataframe\ndt_long_19 &lt;- pivot_longer(\n  dt_temp_19,\n  cols = -c(\"covid_condition\"),\n  names_prefix = \"Trust_in_\",\n  values_to = \"Values\",\n  names_to = \"Attitudes\"\n) |&gt;\n  drop_na()\n\n\n# make graph\nplot_tab_19 &lt;- dt_long_19 |&gt;\n  ggplot2::ggplot(aes(covid_condition, Values, fill = Attitudes)) +\n  labs(title = \"Institutional Trust and Conspiracy Beliefs (1-7)\",\n       subtitle = \"NZAVS 2019/2020  (N = 42,681)\") +\n  geom_boxplot(size = .05, notch = T) +\n  scale_fill_okabe_ito() +\n  facet_grid (. ~ covid_condition, scales = \"free_x\", space = \"free_x\") +\n  theme(legend.position = \"none\") +\n  labs(x = \"Covid Condition\",\n       y = \"Trust response (1-7)\") +\n  theme_classic()\n\n# graph\nplot_tab_19\n\n\n\n\n\n\n\n\nFigure 1: Boxplot for Institutional Trust: NZAVS Waves During Covid: Years 2020\n\n\n\n\n\nThis table and graph compare the trust in science, police, and politicians across three different periods: pre-Covid, lockdown, and post-lockdown.\nWe observe:\n\nTrust in science increased during the lockdown period and remained higher in the post-lockdown period compared to the pre-Covid period.\nTrust in police remained relatively stable across all three periods, although the trend tracked downward after lockdown.\nTrust in politicians increased during the lockdown period. It decreased slightly in the post-lockdown period but remained higher than in the pre-Covid period.\nConspiracy Beliefs: the average mistrust of official versions of major world events given by authorities appear to decrease during lockdown but subsequently decrease.\n\nNotably, the central tendency may not always be the interesting statistic for understanding social change. There may be greater separation in response that is masked by overall average response. In future work, we will examine this point. For now, the trends suggest overall stability during 2019-2020, with increasing confidence in science.\n\n\n\nNext, we examine changes in institutional trust across two waves following the 2019/2020 NZAVS wave.\nTable:\n\n\nShow the code\n#|echo: false\n#|warning: false\n\n\n# this code creates a table\n# functions to make tables simple\n\nmy.render.cont &lt;- function(x) {\n  with(stats.apply.rounding(stats.default(x), digits=3), c(\"\",\n                                                           \"Mean (SD)\"=sprintf(\"%s (&plusmn; %s)\", MEAN, SD)))\n}\n\nmy.render.cat &lt;- function(x) {\n  c(\"\", sapply(stats.default(x), function(y) with(y,\n                                                  sprintf(\"%d (%0.0f %%)\", FREQ, PCT))))\n}\n\n# now the years \ntab_trust &lt;- table1::table1(\n  ~ Trust_in_Science +\n    Trust_in_Politicians +\n    Trust_in_Police + # not measured in 2019-20\n    Trust_in_Govt_Covid_Response + \n    Conspiracy_Beliefs| Wave,\n  data = dt,\n  overall = FALSE,\n  render.continuous = my.render.cont,\n  render.categorical = my.render.cat\n)\n\n\n# needed for markdown tables\ntab_trust &lt;- data.frame( tab_trust )\n\ntab_trust &lt;- tab_trust |&gt; \n    rename(\"Forms of Institutional Trust\" = X.)\n\n\n# graph\ntab_trust |&gt;\n  kbl(format = \"markdown\", booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nForms of Institutional Trust\nX2019\nX2020\nX2021\n\n\n\n\n\n(N=42681)\n(N=42681)\n(N=42681)\n\n\nTrust_in_Science\n\n\n\n\n\nMean (SD)\n5.43 (± 1.28)\n5.67 (± 1.24)\n5.70 (± 1.26)\n\n\nMissing\n375 (0.9%)\n9475 (22.2%)\n14231 (33.3%)\n\n\nTrust_in_Politicians\n\n\n\n\n\nMean (SD)\n3.76 (± 1.45)\n4.05 (± 1.49)\n3.92 (± 1.56)\n\n\nMissing\n853 (2.0%)\n10078 (23.6%)\n15406 (36.1%)\n\n\nTrust_in_Police\n\n\n\n\n\nMean (SD)\n4.58 (± 1.26)\n4.53 (± 1.26)\n4.43 (± 1.30)\n\n\nMissing\n15 (0.0%)\n9378 (22.0%)\n13770 (32.3%)\n\n\nTrust_in_Govt_Covid_Response\n\n\n\n\n\nMean (SD)\nNA (± NA)\n5.66 (± 1.55)\n4.79 (± 1.94)\n\n\nMissing\n42681 (100%)\n9620 (22.5%)\n15123 (35.4%)\n\n\nConspiracy_Beliefs\n\n\n\n\n\nMean (SD)\n4.36 (± 1.63)\n4.10 (± 1.68)\n4.02 (± 1.74)\n\n\nMissing\n1197 (2.8%)\n9676 (22.7%)\n15110 (35.4%)\n\n\n\n\n\nHere is a graph of the same.\n\n\nShow the code\n# transform data into long formate\ndt_temp &lt;- dt |&gt; select(\n  Wave,\n  Trust_in_Science,\n  Trust_in_Politicians,\n  Trust_in_Police,\n  Trust_in_Govt_Covid_Response, \n  Conspiracy_Beliefs\n)\n\n\n# boxplot dataframe\ndt_long &lt;- pivot_longer(\n  dt_temp,\n  cols = -c(\"Wave\"),\n  names_prefix = \"Trust_in_\",\n  values_to = \"Values\",\n  names_to = \"Attitudes\"\n) |&gt;\n  drop_na()\n\n\n# make graph\nplot_tab &lt;- dt_long |&gt;\n  ggplot2::ggplot(aes(Wave, Values, fill = Attitudes)) +\n  labs(title = \"Institutional Trust and Conspiracy Beliefs\",\n       subtitle = \"NZ 2019/21 to 2021/22 [N = 42,681 (at baseline)]\") +\n  geom_boxplot(size = .05, notch = T) +\n  scale_fill_okabe_ito() +\n  facet_grid (. ~ Wave, scales = \"free_x\", space = \"free_x\") +\n  theme(legend.position = \"none\") +\n  labs(y = \"NZAVS Wave (note: waves cross years)\") + \n  theme_classic()\n\n\nplot_tab\n\n\n\n\n\n\n\n\nFigure 2: Boxplot for Institutional Trust: NZAVS Waves 11-13 (years 2019-2022)\n\n\n\n\n\nDescriptive fndings.\nTrust in Science: The average trust score increased from 5.43 (±1.28) in 2019 to 5.67 (±1.24) in 2020 and to 5.70 (±1.26) in 2021. The number of missing values increased from 375 (0.9%) in 2019 to 9,475 (22.2%) in 2020 and further to 14,231 (33.3%) in 2021.\nTrust in Politicians: The average trust score increased from 3.76 (±1.45) in 2019 to 4.05 (±1.49) in 2020, then slightly decreased to 3.92 (±1.56) in 2021. The number of missing values increased from 853 (2.0%) in 2019 to 10,078 (23.6%) in 2020 and further to 15,406 (36.1%) in 2021.\nTrust in Police: The average trust score decreased from 4.58 (±1.26) in 2019 to 4.53 (±1.26) in 2020 and further to 4.43 (±1.30) in 2021. The number of missing values increased from 15 (0.0%) in 2019 to 9,378 (22.0%) in 2020 and further to 13,770 (32.3%) in 2021.\nTrust in Government’s COVID Response: This metric was not applicable in 2019. The average trust score was 5.66 (±1.55) in 2020 and decreased to 4.79 (±1.94) in 2021. The number of missing values was 42,681 (100%) in 2019, 9,620 (22.5%) in 2020, and 15,123 (35.4%) in 2021.\nConspiracy Beliefs: The average score decreased from 4.36 (±1.63) in 2019 to 4.10 (±1.68) in 2020 and further to 4.02 (±1.74) in 2021. The number of missing values increased from 1,197 (2.8%) in 2019 to 9,676 (22.7%) in 2020 and further to 15,110 (35.4%) in 2021.\nHow should we in interpret these findings? Missing data from non-response and panel attrition may bias estimates for the population. We must address bias from missing responses. We address this bias through multiple imputation."
  }
]